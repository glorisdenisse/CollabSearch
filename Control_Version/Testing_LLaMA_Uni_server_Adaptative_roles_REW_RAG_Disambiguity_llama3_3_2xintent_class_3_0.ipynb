{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI9rRfYae-ir",
        "outputId": "122c4fea-0eec-448b-a361-2294371718a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: The directory '/mnt/primary/launcher-cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: The directory '/mnt/primary/launcher-cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: The directory '/mnt/primary/launcher-cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: langchain in /opt/miniconda3/lib/python3.10/site-packages (0.3.27)\n",
            "Requirement already satisfied: openai in /opt/miniconda3/lib/python3.10/site-packages (1.99.0)\n",
            "Requirement already satisfied: google-api-python-client in /opt/miniconda3/lib/python3.10/site-packages (2.177.0)\n",
            "Requirement already satisfied: langchain_community in /opt/miniconda3/lib/python3.10/site-packages (0.3.27)\n",
            "Requirement already satisfied: tools in /opt/miniconda3/lib/python3.10/site-packages (1.0.2)\n",
            "Requirement already satisfied: langchain_google_community in /opt/miniconda3/lib/python3.10/site-packages (2.0.7)\n",
            "Requirement already satisfied: langchain_openai in /opt/miniconda3/lib/python3.10/site-packages (0.3.28)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /opt/miniconda3/lib/python3.10/site-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /opt/miniconda3/lib/python3.10/site-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /opt/miniconda3/lib/python3.10/site-packages (from langchain) (0.4.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/miniconda3/lib/python3.10/site-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/miniconda3/lib/python3.10/site-packages (from langchain) (2.0.42)\n",
            "Requirement already satisfied: requests<3,>=2 in /opt/miniconda3/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /opt/miniconda3/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/miniconda3/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (1.8.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /opt/miniconda3/lib/python3.10/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /opt/miniconda3/lib/python3.10/site-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /opt/miniconda3/lib/python3.10/site-packages (from google-api-python-client) (2.40.3)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/miniconda3/lib/python3.10/site-packages (from google-api-python-client) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /opt/miniconda3/lib/python3.10/site-packages (from google-api-python-client) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/miniconda3/lib/python3.10/site-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/miniconda3/lib/python3.10/site-packages (from langchain_community) (3.11.18)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/miniconda3/lib/python3.10/site-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/miniconda3/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/miniconda3/lib/python3.10/site-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/miniconda3/lib/python3.10/site-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /opt/miniconda3/lib/python3.10/site-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /opt/miniconda3/lib/python3.10/site-packages (from langchain_google_community) (2.4.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.70.0 in /opt/miniconda3/lib/python3.10/site-packages (from langchain_google_community) (1.71.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/miniconda3/lib/python3.10/site-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/miniconda3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /opt/miniconda3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/miniconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/miniconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/miniconda3/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /opt/miniconda3/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (4.25.7)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/miniconda3/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/miniconda3/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/miniconda3/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/miniconda3/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/miniconda3/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.3)\n",
            "Requirement already satisfied: certifi in /opt/miniconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/miniconda3/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /opt/miniconda3/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /opt/miniconda3/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/miniconda3/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /opt/miniconda3/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /opt/miniconda3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/miniconda3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/miniconda3/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
            "Requirement already satisfied: greenlet>=1 in /opt/miniconda3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /opt/miniconda3/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /opt/miniconda3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/miniconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/miniconda3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install openai>=1.0.0 geotext transformers GeoText\n",
        "!pip install -q -U google-genai\n",
        "!pip install langchain openai google-api-python-client langchain_community tools langchain_google_community langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF3PuS14fIGg",
        "outputId": "1b82ef6b-378a-47bc-b338-ae28b68ae9e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: The directory '/mnt/primary/launcher-cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: openai in /opt/miniconda3/lib/python3.10/site-packages (1.99.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (1.8.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /opt/miniconda3/lib/python3.10/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/miniconda3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /opt/miniconda3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: certifi in /opt/miniconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /opt/miniconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/miniconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: The directory '/mnt/primary/launcher-cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: gradio in /opt/miniconda3/lib/python3.10/site-packages (5.40.0)\n",
            "Requirement already satisfied: openpyxl in /opt/miniconda3/lib/python3.10/site-packages (3.1.5)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (1.11.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (3.11.1)\n",
            "Requirement already satisfied: packaging in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (2.2.3)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.12.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /opt/miniconda3/lib/python3.10/site-packages (from gradio-client==1.11.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: et-xmlfile in /opt/miniconda3/lib/python3.10/site-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/miniconda3/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /opt/miniconda3/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /opt/miniconda3/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /opt/miniconda3/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /opt/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /opt/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /opt/miniconda3/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/miniconda3/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /opt/miniconda3/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /opt/miniconda3/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /opt/miniconda3/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniconda3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.0.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (1.26.18)\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/miniconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai\n",
        "!pip install gradio openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DibFVFaDfIq8"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime\n",
        "import logging\n",
        "import csv\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import re\n",
        "from geotext import GeoText\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGOWd1y3fOLj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain import GoogleSearchAPIWrapper\n",
        "from openai import OpenAI\n",
        "from langchain_google_community import GoogleSearchAPIWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import Tool, AgentExecutor, create_tool_calling_agent\n",
        "from langchain.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sui66xUhfUlC"
      },
      "outputs": [],
      "source": [
        "os.environ[\"IDA_LLM_API_KEY\"]=\"your_key_here\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"your_key_here\"\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = \"your_key_here\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faSaeyygNeba"
      },
      "outputs": [],
      "source": [
        "j = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHCvF0cl9hDI"
      },
      "outputs": [],
      "source": [
        "# Initialize your private LLM client (llama-3.3-70b-instruct via university server)\n",
        "client = OpenAI(\n",
        "    base_url=\"http://api.llm.apps.os.dcs.gla.ac.uk/v1\",\n",
        "    api_key=os.environ['IDA_LLM_API_KEY']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JUyXDW7Nebb"
      },
      "outputs": [],
      "source": [
        "def initialize_database():\n",
        "    \"\"\"Initialize the CSV database with all COLA framework columns\"\"\"\n",
        "    if not os.path.exists('cola_database.csv'):\n",
        "        columns = [\n",
        "            'ID', 'Original_Query', 'Rewritten_Query', 'Selected_Topic_Intent', 'Selected_Answer_Type',\n",
        "            'Linguist Analysis', 'Expert Analysis', 'User Analysis', 'In Favor', 'Against',\n",
        "            'Final Judgement', 'After RAG Agent', 'Final Plan',\n",
        "            'Processing_Time_Seconds', 'Processing_Time_Seconds_RAG','Timestamp', 'Status'\n",
        "        ]\n",
        "        df = pd.DataFrame(columns=columns)\n",
        "        # Set proper data types to avoid warnings\n",
        "        df = df.astype({\n",
        "            'ID': 'int64',\n",
        "            'Original_Query': 'string',\n",
        "            'Rewritten_Query': 'string',\n",
        "            'Selected_Topic_Intent': 'string',\n",
        "            'Selected_Answer_Type': 'string',\n",
        "            'Linguist Analysis': 'string',\n",
        "            'Expert Analysis': 'string',\n",
        "            'User Analysis': 'string',\n",
        "            'In Favor': 'string',\n",
        "            'Against': 'string',\n",
        "            'Final Judgement': 'string',\n",
        "            'After RAG Agent': 'string',\n",
        "            'Final Plan': 'string',\n",
        "            'Processing_Time_Seconds': 'float64',\n",
        "            'Processing_Time_Seconds_RAG': 'float64',\n",
        "            'Timestamp': 'string',\n",
        "            'Status': 'string'\n",
        "        })\n",
        "        df.to_csv('cola_database.csv', index=False)\n",
        "        print(\"Enhanced COLA database initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebVtBNw_Nebc"
      },
      "outputs": [],
      "source": [
        "def add_new_query(query_id, query_text):\n",
        "    \"\"\"Add a new query to the database with pending status\"\"\"\n",
        "    try:\n",
        "        if os.path.exists('cola_database.csv'):\n",
        "            df = pd.read_csv('cola_database.csv', dtype={\n",
        "                'ID': 'int64',\n",
        "                'Original_Query': 'string',\n",
        "                'Rewritten_Query': 'string',\n",
        "                'Selected_Topic_Intent': 'string',\n",
        "                'Selected_Answer_Type': 'string',\n",
        "                'Linguist Analysis': 'string',\n",
        "                'Expert Analysis': 'string',\n",
        "                'User Analysis': 'string',\n",
        "                'In Favor': 'string',\n",
        "                'Against': 'string',\n",
        "                'Final Judgement': 'string',\n",
        "                'After RAG Agent': 'string',\n",
        "                'Final Plan': 'string',\n",
        "                'Processing_Time_Seconds': 'float64',\n",
        "                'Processing_Time_Seconds_RAG': 'float64',\n",
        "                'Timestamp': 'string',\n",
        "                'Status': 'string'\n",
        "            })\n",
        "        else:\n",
        "            initialize_database()\n",
        "            df = pd.read_csv('cola_database.csv', dtype={\n",
        "                'ID': 'int64',\n",
        "                'Original_Query': 'string',\n",
        "                'Rewritten_Query': 'string',\n",
        "                'Selected_Topic_Intent': 'string',\n",
        "                'Selected_Answer_Type': 'string',\n",
        "                'Linguist Analysis': 'string',\n",
        "                'Expert Analysis': 'string',\n",
        "                'User Analysis': 'string',\n",
        "                'In Favor': 'string',\n",
        "                'Against': 'string',\n",
        "                'Final Judgement': 'string',\n",
        "                'After RAG Agent': 'string',\n",
        "                'Final Plan': 'string',\n",
        "                'Processing_Time_Seconds': 'float64',\n",
        "                'Processing_Time_Seconds_RAG': 'float64',\n",
        "                'Timestamp': 'string',\n",
        "                'Status': 'string'\n",
        "            })\n",
        "\n",
        "        # Add new query row\n",
        "        new_row = {\n",
        "            'ID': query_id,\n",
        "            'Original_Query': query_text,\n",
        "            'Rewritten_Query': '',\n",
        "            'Selected_Topic_Intent': '',\n",
        "            'Selected_Answer_Type': '',\n",
        "            'Linguist Analysis': '',\n",
        "            'Expert Analysis': '',\n",
        "            'User Analysis': '',\n",
        "            'In Favor': '',\n",
        "            'Against': '',\n",
        "            'Final Judgement': '',\n",
        "            'After RAG Agent': '',\n",
        "            'Final Plan': '',\n",
        "            'Processing_Time_Seconds': None,\n",
        "            'Processing_Time_Seconds_RAG': None,\n",
        "            'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'Status': 'pending'\n",
        "        }\n",
        "\n",
        "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "        df.to_csv('cola_database.csv', index=False)\n",
        "        print(f\"Added query {query_id} to enhanced COLA database\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error adding query to database: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MW_i1fGxNebd"
      },
      "outputs": [],
      "source": [
        "def update_query_results(query_id, results_dict):\n",
        "    \"\"\"Update all COLA results for a specific query ID\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv('cola_database.csv', dtype={\n",
        "            'ID': 'int64',\n",
        "            'Original_Query': 'string',\n",
        "            'Rewritten_Query': 'string',\n",
        "            'Selected_Topic_Intent': 'string',\n",
        "            'Selected_Answer_Type': 'string',\n",
        "            'Linguist Analysis': 'string',\n",
        "            'Expert Analysis': 'string',\n",
        "            'User Analysis': 'string',\n",
        "            'In Favor': 'string',\n",
        "            'Against': 'string',\n",
        "            'Final Judgement': 'string',\n",
        "            'After RAG Agent': 'string',\n",
        "            'Final Plan': 'string',\n",
        "            'Processing_Time_Seconds': 'float64',\n",
        "            'Processing_Time_Seconds_RAG': 'float64',\n",
        "            'Timestamp': 'string',\n",
        "            'Status': 'string'\n",
        "        })\n",
        "\n",
        "        # Find the row with the specific ID\n",
        "        mask = df['ID'] == query_id\n",
        "        if mask.any():\n",
        "            # Update all columns with results - convert values to proper types\n",
        "            for column, value in results_dict.items():\n",
        "                if column in df.columns:\n",
        "                    if column == 'Processing_Time_Seconds' and value is not None:\n",
        "                        df.loc[mask, column] = float(value)\n",
        "                    else:\n",
        "                        df.loc[mask, column] = str(value) if value is not None else ''\n",
        "\n",
        "            df.loc[mask, 'Status'] = 'completed'\n",
        "            df.to_csv('cola_database.csv', index=False)\n",
        "            print(f\"Updated all results for query {query_id}\")\n",
        "        else:\n",
        "            print(f\"Query ID {query_id} not found in database\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error updating results in database: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcPsHj_Yfhvt"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt):\n",
        "    max_retries = 100\n",
        "\n",
        "    for i in range(max_retries):\n",
        "        try:\n",
        "          messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "          response = client.chat.completions.create(\n",
        "              model=\"llama-3.3-70b-instruct\",\n",
        "              messages=messages,\n",
        "              temperature=0\n",
        "            )\n",
        "          return response.choices[0].message.content\n",
        "        except Exception as e:  # Generic exception handling\n",
        "            if i < max_retries - 1:\n",
        "                time.sleep(2)\n",
        "                logging.warning(f\"Attempt {i+1} failed: {e}\")\n",
        "            else:\n",
        "                logging.error(f'Max retries reached for prompt: {instruction}. Error: {e}')\n",
        "                return \"Error\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzsEcMKwffxy"
      },
      "outputs": [],
      "source": [
        "def get_completion_with_role(role, instruction, content):\n",
        "    max_retries = 100\n",
        "    for i in range(max_retries):\n",
        "      try:\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"You are a {role}.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"{instruction}\\n{content}\"}\n",
        "        ]\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"llama-3.3-70b-instruct\",\n",
        "            messages=messages,\n",
        "            temperature=0\n",
        "          )\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "      except Exception as e:  # Generic exception handling\n",
        "            if i < max_retries - 1:\n",
        "                time.sleep(2)\n",
        "                logging.warning(f\"Attempt {i+1} failed: {e}\")\n",
        "            else:\n",
        "                logging.error(f'Max retries reached for prompt: {instruction}. Error: {e}')\n",
        "                return \"Error\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iABLsdjNebf"
      },
      "outputs": [],
      "source": [
        "def generate_intent_options(original_query):\n",
        "    \"\"\"\n",
        "    Generate 3 most likely DOMAIN/TOPIC interpretations for the original query.\n",
        "    This disambiguates between completely different subjects, not just different angles.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"Query: \"{original_query}\"\n",
        "\n",
        "        CRITICAL: I need you to identify if this query has AMBIGUOUS WORDS that could mean completely different things.\n",
        "\n",
        "        Look for words that could be:\n",
        "        - Programming language vs. place vs. other meanings (Java, Python, Ruby, etc.)\n",
        "        - Company vs. fruit vs. other (Apple, Orange, etc.)\n",
        "        - Person vs. place vs. concept (Tesla, Darwin, etc.)\n",
        "        - Multiple different meanings entirely\n",
        "\n",
        "        If you find ambiguous words, give me 3 DIFFERENT DOMAINS/SUBJECTS.\n",
        "        If no ambiguous words, give me 3 different CONTEXTS for the same topic.\n",
        "\n",
        "        WRONG (all same domain):\n",
        "        - Java web development features\n",
        "        - Java mobile app development\n",
        "        - Java enterprise applications\n",
        "\n",
        "        RIGHT (different domains):\n",
        "        - Java (programming language)\n",
        "        - Java (Indonesian island)\n",
        "        - Java (coffee culture)\n",
        "\n",
        "        Format: Topic (context)\n",
        "\n",
        "        Respond with exactly 3 lines, no explanations:\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = get_completion(prompt)\n",
        "\n",
        "        # Clean and parse the response - be more aggressive about filtering\n",
        "        lines = [line.strip() for line in response.strip().split('\\n') if line.strip()]\n",
        "\n",
        "        options = []\n",
        "        # More comprehensive filtering for instruction text\n",
        "        skip_phrases = [\n",
        "            \"here are\", \"results\", \"the query\", \"could refer\", \"examples\",\n",
        "            \"format\", \"write only\", \"respond with\", \"provide\", \"interpretations\",\n",
        "            \"different meanings\", \"ambiguous\", \"critical\"\n",
        "        ]\n",
        "\n",
        "        for line in lines:\n",
        "            # Skip lines that contain instruction-like phrases\n",
        "            line_lower = line.lower()\n",
        "            if any(phrase in line_lower for phrase in skip_phrases):\n",
        "                continue\n",
        "\n",
        "            # Remove numbering/bullets more aggressively\n",
        "            cleaned_line = line\n",
        "            import re\n",
        "            cleaned_line = re.sub(r'^[0-9]+[\\.\\)\\-\\s]+', '', cleaned_line)\n",
        "            cleaned_line = re.sub(r'^[\\-\\*\\•]\\s+', '', cleaned_line)\n",
        "\n",
        "            # Only keep lines that look like actual topic options (should contain parentheses ideally)\n",
        "            if cleaned_line and len(cleaned_line) > 3 and not any(phrase in cleaned_line.lower() for phrase in skip_phrases):\n",
        "                options.append(cleaned_line)\n",
        "\n",
        "        # Take first 3 options\n",
        "        if len(options) >= 3:\n",
        "            return options[:3]\n",
        "\n",
        "        # If we don't get good results, create manual disambiguation for common terms\n",
        "        query_lower = original_query.lower()\n",
        "\n",
        "        # Check for common ambiguous terms\n",
        "        if 'java' in query_lower:\n",
        "            return [\n",
        "                \"Java (programming language)\",\n",
        "                \"Java (Indonesian island)\",\n",
        "                \"Java (coffee culture)\"\n",
        "            ]\n",
        "        elif 'python' in query_lower:\n",
        "            return [\n",
        "                \"Python (programming language)\",\n",
        "                \"Python (snake species)\",\n",
        "                \"Python (Monty Python comedy)\"\n",
        "            ]\n",
        "        elif 'tesla' in query_lower:\n",
        "            return [\n",
        "                \"Tesla (car company)\",\n",
        "                \"Tesla (Nikola Tesla scientist)\",\n",
        "                \"Tesla (band/music)\"\n",
        "            ]\n",
        "        else:\n",
        "            # Generic contextual fallback\n",
        "            return [\n",
        "                f\"Technical/professional information about {original_query}\",\n",
        "                f\"General educational information about {original_query}\",\n",
        "                f\"Practical applications of {original_query}\"\n",
        "            ]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating intent options: {e}\")\n",
        "        return [\n",
        "            f\"Technical information about {original_query}\",\n",
        "            f\"General information about {original_query}\",\n",
        "            f\"Practical guide for {original_query}\"\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjKzelhNNebg"
      },
      "outputs": [],
      "source": [
        "def process_selected_intent(selected_option, original_query, query_id, chatbot_history, state):\n",
        "    \"\"\"\n",
        "    Process the user's selected intent and continue with COLA framework.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Show confirmation of selection in simple text\n",
        "        confirmation_msg = f\"\\n\\n✅ **Selected Intent:** {selected_option}\\n\\n🤔 Processing through COLA framework...\"\n",
        "\n",
        "        confirmation_message = {\"role\": \"assistant\", \"content\": confirmation_msg}\n",
        "        temp_history = chatbot_history + [confirmation_message]\n",
        "\n",
        "        yield temp_history, state, \"\"\n",
        "\n",
        "        # Now process with the selected intent as the working query\n",
        "        answer = add_predictions_sequential(original_query, selected_option, query_id)\n",
        "\n",
        "        # Replace confirmation with final result\n",
        "        final_message = {\"role\": \"assistant\", \"content\": str(answer)}\n",
        "        final_history = chatbot_history + [final_message]\n",
        "        final_state = state + [final_message]\n",
        "\n",
        "        yield final_history, final_state, \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"\\n\\n❌ **Error processing selected intent:** {str(e)}\"\n",
        "        error_message = {\"role\": \"assistant\", \"content\": error_msg}\n",
        "        error_history = chatbot_history + [error_message]\n",
        "        error_state = state + [error_message]\n",
        "        yield error_history, error_state, \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQvfDDo3Nebg"
      },
      "outputs": [],
      "source": [
        "def show_intent_options(chatbot_history, state, options):\n",
        "    \"\"\"\n",
        "    Display intent options to user for selection using simple text format.\n",
        "    Returns updated chat history with the options.\n",
        "    \"\"\"\n",
        "    # Use simple markdown formatting instead of HTML\n",
        "    options_text = \"🎯 **Please clarify your intent:**\\n\\n\"\n",
        "    options_text += \"Select the option that best matches what you're looking for:\\n\\n\"\n",
        "\n",
        "    for i, option in enumerate(options, 1):\n",
        "        options_text += f\"**Option {i}:** {option}\\n\\n\"\n",
        "\n",
        "    options_text += \"👇 **Click the corresponding Option button below the chat to proceed.**\"\n",
        "\n",
        "    # Add the options message to chat\n",
        "    intent_message = {\"role\": \"assistant\", \"content\": options_text}\n",
        "    updated_history = chatbot_history + [intent_message]\n",
        "    updated_state = state + [intent_message]\n",
        "\n",
        "    return updated_history, updated_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sa-MXPf9Nebh"
      },
      "outputs": [],
      "source": [
        "def generate_answer_type_options(query, selected_topic_intent):\n",
        "    \"\"\"\n",
        "    Generate answer type options based on the query and selected topic intent.\n",
        "    This helps clarify what kind of response the user is looking for.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"Query: \"{query}\"\n",
        "        Selected Topic: \"{selected_topic_intent}\"\n",
        "\n",
        "        The user wants to know about this topic. What type of answer would be most helpful?\n",
        "\n",
        "        Generate 3 different ANSWER TYPE options that would be appropriate for this query:\n",
        "\n",
        "        Consider these categories:\n",
        "        - Informative (detailed explanation, facts, background information)\n",
        "        - Practical Tips (actionable advice, how-to guidance, steps to follow)\n",
        "        - Basic Overview (simple introduction, key points, beginner-friendly)\n",
        "        - Expert Analysis (in-depth professional perspective, technical details)\n",
        "        - Comparison/Evaluation (pros/cons, alternatives, recommendations)\n",
        "        - Problem-Solving (solutions, troubleshooting, addressing specific issues)\n",
        "\n",
        "        Format each option as: \"Answer Type (brief description)\"\n",
        "\n",
        "        Examples:\n",
        "        - Informative (comprehensive background and facts)\n",
        "        - Practical Tips (step-by-step actionable guidance)\n",
        "        - Basic Overview (simple introduction for beginners)\n",
        "\n",
        "        Respond with exactly 3 lines, no explanations:\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = get_completion(prompt)\n",
        "\n",
        "        # Parse response similar to intent options\n",
        "        lines = [line.strip() for line in response.strip().split('\\n') if line.strip()]\n",
        "\n",
        "        options = []\n",
        "        skip_phrases = [\n",
        "            \"here are\", \"results\", \"the query\", \"could refer\", \"examples\",\n",
        "            \"format\", \"write only\", \"respond with\", \"provide\", \"options\",\n",
        "            \"different types\", \"answer type\"\n",
        "        ]\n",
        "\n",
        "        for line in lines:\n",
        "            line_lower = line.lower()\n",
        "            if any(phrase in line_lower for phrase in skip_phrases):\n",
        "                continue\n",
        "\n",
        "            # Remove numbering/bullets\n",
        "            import re\n",
        "            cleaned_line = re.sub(r'^[0-9]+[\\.\\)\\-\\s]+', '', line)\n",
        "            cleaned_line = re.sub(r'^[\\-\\*\\•]\\s+', '', cleaned_line)\n",
        "\n",
        "            if cleaned_line and len(cleaned_line) > 3:\n",
        "                options.append(cleaned_line)\n",
        "\n",
        "        # Take first 3 options\n",
        "        if len(options) >= 3:\n",
        "            return options[:3]\n",
        "\n",
        "        # Fallback options based on query analysis\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        if any(word in query_lower for word in ['how to', 'steps', 'guide', 'tutorial']):\n",
        "            return [\n",
        "                \"Practical Tips (step-by-step actionable guidance)\",\n",
        "                \"Informative (detailed explanation and background)\",\n",
        "                \"Basic Overview (simple introduction for beginners)\"\n",
        "            ]\n",
        "        elif any(word in query_lower for word in ['what is', 'explain', 'about']):\n",
        "            return [\n",
        "                \"Informative (comprehensive background and facts)\",\n",
        "                \"Basic Overview (simple introduction for beginners)\",\n",
        "                \"Expert Analysis (in-depth professional perspective)\"\n",
        "            ]\n",
        "        else:\n",
        "            # Generic fallback\n",
        "            return [\n",
        "                \"Informative (comprehensive background and facts)\",\n",
        "                \"Practical Tips (actionable advice and guidance)\",\n",
        "                \"Basic Overview (simple introduction and key points)\"\n",
        "            ]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating answer type options: {e}\")\n",
        "        return [\n",
        "            \"Informative (comprehensive background and facts)\",\n",
        "            \"Practical Tips (actionable advice and guidance)\",\n",
        "            \"Basic Overview (simple introduction and key points)\"\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bpMKV7CNebi"
      },
      "outputs": [],
      "source": [
        "def show_answer_type_options(chatbot_history, state, options):\n",
        "    \"\"\"\n",
        "    Display answer type options to user for selection.\n",
        "    \"\"\"\n",
        "    options_text = \"📝 **What type of answer would you like?**\\n\\n\"\n",
        "    options_text += \"Select the format that best matches what you're looking for:\\n\\n\"\n",
        "\n",
        "    for i, option in enumerate(options, 1):\n",
        "        options_text += f\"**Type {i}:** {option}\\n\\n\"\n",
        "\n",
        "    options_text += \"👇 **Click the corresponding Type button below the chat to proceed.**\"\n",
        "\n",
        "    # Add the options message to chat\n",
        "    answer_type_message = {\"role\": \"assistant\", \"content\": options_text}\n",
        "    updated_history = chatbot_history + [answer_type_message]\n",
        "    updated_state = state + [answer_type_message]\n",
        "\n",
        "    return updated_history, updated_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtci-6zYNebi"
      },
      "outputs": [],
      "source": [
        "def process_selected_answer_type(selected_answer_type, selected_topic_intent, original_query, query_id, chatbot_history, state):\n",
        "    \"\"\"\n",
        "    Process the user's selected answer type and continue with COLA framework.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Show confirmation of selection\n",
        "        confirmation_msg = f\"✅ **Selected Topic:** {selected_topic_intent}\\n\"\n",
        "        confirmation_msg += f\"✅ **Selected Answer Type:** {selected_answer_type}\\n\\n\"\n",
        "        confirmation_msg += \"🤔 Processing through COLA framework...\"\n",
        "\n",
        "        confirmation_message = {\"role\": \"assistant\", \"content\": confirmation_msg}\n",
        "        temp_history = chatbot_history + [confirmation_message]\n",
        "\n",
        "        yield temp_history, state, \"\"\n",
        "\n",
        "        # Now process with both clarifications\n",
        "        answer = add_predictions_sequential_enhanced(original_query, selected_topic_intent, selected_answer_type, query_id)\n",
        "\n",
        "        # Replace confirmation with final result\n",
        "        final_message = {\"role\": \"assistant\", \"content\": str(answer)}\n",
        "        final_history = chatbot_history + [final_message]\n",
        "        final_state = state + [final_message]\n",
        "\n",
        "        yield final_history, final_state, \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"\\n\\n❌ **Error processing selected answer type:** {str(e)}\"\n",
        "        error_message = {\"role\": \"assistant\", \"content\": error_msg}\n",
        "        error_history = chatbot_history + [error_message]\n",
        "        error_state = state + [error_message]\n",
        "        yield error_history, error_state, \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CrJQTaZNebj"
      },
      "outputs": [],
      "source": [
        "def rewrite_query_with_dual_intent(original_query, selected_topic, selected_answer_type):\n",
        "    \"\"\"\n",
        "    Rewrite the query using both the selected topic and desired answer type.\n",
        "    This creates a comprehensive query that guides the COLA framework appropriately.\n",
        "    \"\"\"\n",
        "    # Extract the main answer type from the selection\n",
        "    answer_type_main = selected_answer_type.split('(')[0].strip()\n",
        "    answer_type_description = selected_answer_type.split('(')[1].strip(')') if '(' in selected_answer_type else \"\"\n",
        "\n",
        "    instruction = f\"\"\"You have an original user query, their selected topic/domain, and their desired answer type.\n",
        "\n",
        "    Create a single, clear, and comprehensive query that:\n",
        "    - Focuses specifically on the selected topic/domain: {selected_topic}\n",
        "    - Indicates the type of response they want: {answer_type_main}\n",
        "    - Preserves the user's original intent\n",
        "    - Is suitable for expert analysis\n",
        "    - Guides experts to provide the right format of response\n",
        "\n",
        "    The rewritten query should naturally incorporate both the topic focus and the answer type preference.\n",
        "\n",
        "    Examples:\n",
        "    - Original: \"tell me about java\" + Topic: \"Java (programming)\" + Type: \"Practical Tips\"\n",
        "      → \"Provide practical tips and actionable guidance for learning and working with Java programming language\"\n",
        "\n",
        "    - Original: \"what is bitcoin\" + Topic: \"Bitcoin (cryptocurrency)\" + Type: \"Basic Overview\"\n",
        "      → \"Give a basic overview and introduction to Bitcoin cryptocurrency for beginners\"\n",
        "\n",
        "    Respond with ONLY the rewritten query. Do not include explanations or formatting.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"{instruction}\n",
        "\n",
        "    Original Query: \"{original_query}\"\n",
        "    Selected Topic/Domain: \"{selected_topic}\"\n",
        "    Selected Answer Type: \"{selected_answer_type}\"\n",
        "\n",
        "    Rewritten Query:\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = get_completion(prompt)\n",
        "        # Clean up the response\n",
        "        cleaned_response = response.strip().strip('\"').strip(\"'\")\n",
        "\n",
        "        # Remove common prefixes if they appear\n",
        "        prefixes_to_remove = [\"Rewrite:\", \"Rewritten Query:\", \"Query:\", \"Rewritten:\"]\n",
        "        for prefix in prefixes_to_remove:\n",
        "            if cleaned_response.startswith(prefix):\n",
        "                cleaned_response = cleaned_response[len(prefix):].strip()\n",
        "\n",
        "        return cleaned_response if cleaned_response else f\"{selected_topic} - {answer_type_main}\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error in dual intent query rewriting: {e}\")\n",
        "        return f\"{selected_topic} - {answer_type_main}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmKIStBFNebk"
      },
      "outputs": [],
      "source": [
        "#GET ROLES\n",
        "def get_roles(query):\n",
        "    max_retries = 100\n",
        "    prompt_roles = f\"\"\"Act as Recruiting Manager, considering the content of the query you are reading {query}, to what topic does\n",
        "                    the question refer to and provide 3 expert roles to analyze how to solve the question.\n",
        "                    These 3 roles should have different perspectives.\n",
        "\n",
        "                    Return ONLY a Python list in this exact format:\n",
        "                    [\"topic name\", \"expert role 1\", \"expert role 2\", \"expert role 3\"]\n",
        "\n",
        "                    Do not include any other text, explanations, or formatting. Just the list.\"\"\"\n",
        "    for i in range(max_retries):\n",
        "        try:\n",
        "          messages = [{\"role\": \"user\", \"content\": prompt_roles}]\n",
        "          response = client.chat.completions.create(\n",
        "              model=\"llama-3.3-70b-instruct\",\n",
        "              messages=messages,\n",
        "              temperature=0\n",
        "            )\n",
        "          return response.choices[0].message.content\n",
        "        except Exception as e:  # Generic exception handling\n",
        "            if i < max_retries - 1:\n",
        "                time.sleep(2)\n",
        "                logging.warning(f\"Attempt {i+1} failed: {e}\")\n",
        "            else:\n",
        "                logging.error(f'Max retries reached for prompt: {instruction}. Error: {e}')\n",
        "                return \"Error\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tu5xvck9fjdz"
      },
      "outputs": [],
      "source": [
        "def local_analysis_enhanced(query, topic, answer_type):\n",
        "    \"\"\"Enhanced local analysis with answer type consideration\"\"\"\n",
        "    role = target_role_map.get(\"Local\")\n",
        "\n",
        "    # Extract the main answer type from the selection\n",
        "    answer_type_main = answer_type.split('(')[0].strip()\n",
        "\n",
        "    instruction = f\"\"\"You are a {role} with deep knowledge about {topic}.\n",
        "\n",
        "    User Query: \"{query}\"\n",
        "    Requested Answer Type: {answer_type}\n",
        "\n",
        "    As a {role}, provide your professional analysis addressing this query.\n",
        "\n",
        "    IMPORTANT: Format your response as {answer_type_main.upper()}:\n",
        "\n",
        "    {get_answer_type_instructions(answer_type_main)}\n",
        "\n",
        "    Your response should reflect the expertise and viewpoint that defines your role as a {role} while following the requested answer format.\"\"\"\n",
        "\n",
        "    return get_completion_with_role(role, instruction, query)\n",
        "\n",
        "def expert_analysis_enhanced(query, topic, answer_type):\n",
        "    \"\"\"Enhanced expert analysis with answer type consideration\"\"\"\n",
        "    role = target_role_map.get(\"Expert\")\n",
        "    answer_type_main = answer_type.split('(')[0].strip()\n",
        "\n",
        "    instruction = f\"\"\"You are a {role} specializing in {topic}.\n",
        "\n",
        "    User Query: \"{query}\"\n",
        "    Requested Answer Type: {answer_type}\n",
        "\n",
        "    Provide your professional expert analysis of this query.\n",
        "\n",
        "    IMPORTANT: Format your response as {answer_type_main.upper()}:\n",
        "\n",
        "    {get_answer_type_instructions(answer_type_main)}\n",
        "\n",
        "    Your analysis should reflect the authority and comprehensive understanding that comes from being a recognized {role} in this domain.\"\"\"\n",
        "\n",
        "    return get_completion_with_role(role, instruction, query)\n",
        "\n",
        "def user_analysis_enhanced(query, topic, answer_type):\n",
        "    \"\"\"Enhanced user analysis with answer type consideration\"\"\"\n",
        "    role = target_role_map.get(\"User Analysis\")\n",
        "    answer_type_main = answer_type.split('(')[0].strip()\n",
        "\n",
        "    instruction = f\"\"\"You are a {role} with expertise in {topic}.\n",
        "\n",
        "    User Query: \"{query}\"\n",
        "    Requested Answer Type: {answer_type}\n",
        "\n",
        "    Analyze this query from your specialized perspective as a {role}.\n",
        "\n",
        "    IMPORTANT: Format your response as {answer_type_main.upper()}:\n",
        "\n",
        "    {get_answer_type_instructions(answer_type_main)}\n",
        "\n",
        "    Your analysis should complement other expert perspectives while offering the distinct value that only a {role} can provide.\"\"\"\n",
        "\n",
        "    return get_completion_with_role(role, instruction, query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsAFpv_vNebl"
      },
      "outputs": [],
      "source": [
        "def get_answer_type_instructions(answer_type):\n",
        "    \"\"\"Get specific instructions based on answer type\"\"\"\n",
        "    instructions = {\n",
        "        \"Informative\": \"\"\"\n",
        "        - Provide comprehensive background information and facts\n",
        "        - Include detailed explanations and context\n",
        "        - Cover multiple aspects of the topic\n",
        "        - Use evidence and examples to support points\n",
        "        - Structure information clearly and logically\"\"\",\n",
        "\n",
        "        \"Practical Tips\": \"\"\"\n",
        "        - Focus on actionable advice and guidance\n",
        "        - Provide step-by-step instructions where applicable\n",
        "        - Include specific recommendations and best practices\n",
        "        - Emphasize what the user can actually do\n",
        "        - Make suggestions concrete and implementable\"\"\",\n",
        "\n",
        "        \"Basic Overview\": \"\"\"\n",
        "        - Keep explanations simple and accessible\n",
        "        - Focus on key points and essential information\n",
        "        - Avoid technical jargon or complex details\n",
        "        - Provide a clear, easy-to-understand introduction\n",
        "        - Structure information in a beginner-friendly way\"\"\",\n",
        "\n",
        "        \"Expert Analysis\": \"\"\"\n",
        "        - Provide in-depth professional perspective\n",
        "        - Include technical details and advanced insights\n",
        "        - Reference industry standards and best practices\n",
        "        - Demonstrate specialized knowledge and expertise\n",
        "        - Address complex aspects and nuances\"\"\",\n",
        "\n",
        "        \"Comparison\": \"\"\"\n",
        "        - Present pros and cons clearly\n",
        "        - Compare different options or approaches\n",
        "        - Provide balanced evaluation of alternatives\n",
        "        - Include recommendations based on comparison\n",
        "        - Help user understand trade-offs\"\"\",\n",
        "\n",
        "        \"Problem-Solving\": \"\"\"\n",
        "        - Focus on solutions and troubleshooting\n",
        "        - Address specific issues and challenges\n",
        "        - Provide practical problem-solving approaches\n",
        "        - Include preventive measures where applicable\n",
        "        - Emphasize resolution strategies\"\"\"\n",
        "    }\n",
        "\n",
        "    return instructions.get(answer_type, instructions[\"Informative\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYr76UCYNebl"
      },
      "outputs": [],
      "source": [
        "def stance_analysis_enhanced(query, ling_response, expert_response, user_response, topic, stance, answer_type):\n",
        "    \"\"\"Enhanced stance analysis that considers answer type\"\"\"\n",
        "    role_1 = target_role_map.get(\"Local\")\n",
        "    role_2 = target_role_map.get(\"Expert\")\n",
        "    role_3 = target_role_map.get(\"User Analysis\")\n",
        "\n",
        "    stance_context = {\n",
        "        \"positive\": \"highly beneficial, well-founded, and strongly recommended\",\n",
        "        \"negative\": \"problematic, risky, or not advisable\"\n",
        "    }\n",
        "\n",
        "    stance_description = stance_context.get(stance, stance)\n",
        "    answer_type_main = answer_type.split('(')[0].strip()\n",
        "\n",
        "    prompt = f\"\"\"You are conducting stance detection analysis for collaborative decision-making.\n",
        "\n",
        "    Original Query: '''{query}'''\n",
        "    Topic: {topic}\n",
        "    Requested Answer Type: {answer_type}\n",
        "\n",
        "    EXPERT ANALYSES:\n",
        "    From {role_1}: <<<{ling_response}>>>\n",
        "    From {role_2}: [[[{expert_response}]]]\n",
        "    From {role_3}: ---{user_response}---\n",
        "\n",
        "    YOUR STANCE: You believe the approaches, recommendations, or solutions presented in response to this query are {stance_description} for the user's situation regarding {topic}.\n",
        "\n",
        "    IMPORTANT: Your argument should be formatted as {answer_type_main.upper()} since that's what the user requested.\n",
        "\n",
        "    {get_answer_type_instructions(answer_type_main)}\n",
        "\n",
        "    TASK:\n",
        "    1. **Analyze all three expert perspectives** through your {stance} lens\n",
        "    2. **Extract supporting evidence** that supports your {stance} position\n",
        "    3. **Build your argument** using evidence while following the {answer_type_main} format\n",
        "\n",
        "    Present your {stance} argument with specific evidence from the expert analyses, formatted according to the user's requested answer type.\"\"\"\n",
        "\n",
        "    return get_completion(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYiW_AxiflSw"
      },
      "outputs": [],
      "source": [
        "def final_judgement(query, favor_response, against_response, topic):\n",
        "    \"\"\"\n",
        "    Enhanced final judgement that synthesizes collaborative analysis\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"You are the final decision-maker in a collaborative analysis system. Your role is to synthesize multiple expert perspectives and opposing viewpoints to provide the best possible response to the user.\n",
        "\n",
        "    USER QUERY: \"{query}\"\n",
        "    TOPIC AREA: {topic}\n",
        "\n",
        "    COLLABORATIVE ANALYSIS RESULTS:\n",
        "\n",
        "    POSITIVE PERSPECTIVE (Supporting Arguments):\n",
        "    {favor_response}\n",
        "\n",
        "    NEGATIVE PERSPECTIVE (Cautionary Arguments):\n",
        "    {against_response}\n",
        "\n",
        "    YOUR TASK:\n",
        "    Synthesize these collaborative analyses to provide the optimal response to the user's query. This means:\n",
        "\n",
        "    1. **Evaluate evidence quality**: Assess the strength and credibility of arguments from both sides\n",
        "    2. **Consider user context**: Focus on what would be most beneficial for someone asking this specific query\n",
        "    3. **Balance perspectives**: Integrate the strongest insights from both positive and negative analyses\n",
        "    4. **Provide actionable guidance**: Give the user clear, practical direction\n",
        "\n",
        "    OUTPUT REQUIREMENTS:\n",
        "    - Deliver a comprehensive yet concise response\n",
        "    - Be definitive while acknowledging important considerations\n",
        "    - Focus on practical value for the user\n",
        "    - Integrate insights from the collaborative analysis\n",
        "    - Present as the authoritative answer to their query\n",
        "    - Give a brief, practical response (1-2 paragraphs).\n",
        "\n",
        "    Your response should represent the best collective wisdom from the collaborative analysis process.\"\"\"\n",
        "\n",
        "    judgement = get_completion(prompt)\n",
        "    return judgement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7alYPKN7fnYQ"
      },
      "outputs": [],
      "source": [
        "def final_judgement_enhanced(query, favor_response, against_response, topic, answer_type):\n",
        "    \"\"\"Enhanced final judgement that considers answer type\"\"\"\n",
        "    answer_type_main = answer_type.split('(')[0].strip()\n",
        "\n",
        "    prompt = f\"\"\"You are the final decision-maker in a collaborative analysis system. Your role is to synthesize multiple expert perspectives and opposing viewpoints to provide the best possible response to the user.\n",
        "\n",
        "    USER QUERY: \"{query}\"\n",
        "    TOPIC AREA: {topic}\n",
        "    REQUESTED ANSWER TYPE: {answer_type}\n",
        "\n",
        "    COLLABORATIVE ANALYSIS RESULTS:\n",
        "\n",
        "    POSITIVE PERSPECTIVE (Supporting Arguments):\n",
        "    {favor_response}\n",
        "\n",
        "    NEGATIVE PERSPECTIVE (Cautionary Arguments):\n",
        "    {against_response}\n",
        "\n",
        "    YOUR TASK:\n",
        "    Synthesize these collaborative analyses to provide the optimal response to the user's query.\n",
        "\n",
        "    CRITICAL: Format your response as {answer_type_main.upper()} as specifically requested by the user:\n",
        "\n",
        "    {get_answer_type_instructions(answer_type_main)}\n",
        "\n",
        "    OUTPUT REQUIREMENTS:\n",
        "    - Follow the {answer_type_main} format strictly\n",
        "    - Integrate insights from the collaborative analysis\n",
        "    - Focus on practical value for the user\n",
        "    - Be definitive while acknowledging important considerations\n",
        "    - Present as the authoritative answer to their query\n",
        "\n",
        "    Your response should represent the best collective wisdom from the collaborative analysis process, delivered in exactly the format the user requested.\"\"\"\n",
        "\n",
        "    judgement = get_completion(prompt)\n",
        "    return judgement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_SIbeQC9hDI",
        "outputId": "b39b748d-ef4c-4c9f-e94e-6c772993f3e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Private LLM Response: Data + Algorithms = Insights\n"
          ]
        }
      ],
      "source": [
        "# Test your private LLM\n",
        "def test_private_llm():\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-instruct\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": \"Explain how AI works in a few words\"}\n",
        "        ]\n",
        "    )\n",
        "    print(\"Private LLM Response:\", response.choices[0].message.content)\n",
        "\n",
        "test_private_llm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAHVfzy8fsM3"
      },
      "outputs": [],
      "source": [
        "search_tool = GoogleSearchAPIWrapper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QufH0dImfsuU"
      },
      "outputs": [],
      "source": [
        "# SIMPLE APPROACH: Use your private LLM directly with LangChain\n",
        "# Since your server uses OpenAI syntax, you can use ChatOpenAI directly!\n",
        "private_llm = ChatOpenAI(\n",
        "    base_url=\"http://api.llm.apps.os.dcs.gla.ac.uk/v1\",\n",
        "    api_key=os.environ['IDA_LLM_API_KEY'],\n",
        "    model=\"llama-3.3-70b-instruct\",\n",
        "    temperature=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVjlJzri9hDJ"
      },
      "outputs": [],
      "source": [
        "# Create the agent with your private LLM\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful travel assistant. When you need current information, use the web_search tool.\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4APvm0z3fuL9"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"web_search\",\n",
        "        func=search_tool.run,\n",
        "        description=\"Fetches real-time information via web search.\",\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg4r5v0Y9hDK"
      },
      "outputs": [],
      "source": [
        "agent = create_tool_calling_agent(private_llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9p9sXiW9hDK"
      },
      "outputs": [],
      "source": [
        "def simple_rag_with_private_llm(query):\n",
        "    \"\"\"\n",
        "    Improved RAG function with better search query extraction\n",
        "    \"\"\"\n",
        "    print(f\"RAG processing query: {query[:100]}...\")\n",
        "\n",
        "    try:\n",
        "        # Extract key search terms from the complex query\n",
        "        # Look for the original user query in the prompt\n",
        "        if 'USER\\'S QUERY:' in query:\n",
        "            # Extract the actual user query for searching\n",
        "            lines = query.split('\\n')\n",
        "            for line in lines:\n",
        "                if 'USER\\'S QUERY:' in line:\n",
        "                    user_query = line.split('USER\\'S QUERY:')[1].strip().strip('\"')\n",
        "                    search_query = user_query\n",
        "                    break\n",
        "        elif 'QUERY:' in query:\n",
        "            lines = query.split('\\n')\n",
        "            for line in lines:\n",
        "                if 'QUERY:' in line and not 'USER\\'S' in line:\n",
        "                    search_query = line.split('QUERY:')[1].strip().strip('\"')\n",
        "                    break\n",
        "        else:\n",
        "            # Fallback - use first 50 characters\n",
        "            search_query = query[:50]\n",
        "\n",
        "        print(f\"Extracted search query: {search_query}\")\n",
        "\n",
        "        # Search with the extracted query\n",
        "        search_results = search_tool.run(search_query)\n",
        "        print(f\"Search results: {search_results[:200]}...\")\n",
        "\n",
        "        # Check if search was successful\n",
        "        if \"No good Google Search Result was found\" in search_results:\n",
        "            print(\"No search results found, providing response based on original recommendation\")\n",
        "            return \"Based on current information, the original expert recommendation remains valid. No significant updates or changes were found that would alter the core advice provided.\"\n",
        "\n",
        "        # Enhanced RAG prompt for better synthesis\n",
        "        rag_prompt = f\"\"\"Based on the search results, enhance and validate the expert recommendation.\n",
        "\n",
        "        ORIGINAL EXPERT RECOMMENDATION: {query}\n",
        "\n",
        "        CURRENT SEARCH RESULTS:\n",
        "        {search_results}\n",
        "\n",
        "        TASK: Use these search results to validate, update, and enhance the expert recommendation. Focus on:\n",
        "        - Current accuracy of the information\n",
        "        - Recent developments or changes\n",
        "        - Specific details that improve the recommendation\n",
        "        - Any corrections needed based on current data\n",
        "\n",
        "        Provide a clear, enhanced recommendation.\"\"\"\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"llama-3.3-70b-instruct\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a research analyst who validates expert recommendations using current search results. Focus on practical improvements and current accuracy.\"},\n",
        "                {\"role\": \"user\", \"content\": rag_prompt}\n",
        "            ],\n",
        "            temperature=0\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"RAG search error: {e}\")\n",
        "        return \"Unable to retrieve current information for validation. The original expert recommendation stands as provided.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9jzU1ET9hDK"
      },
      "outputs": [],
      "source": [
        "# Agent-based RAG function\n",
        "def agent_rag_with_private_llm(query):\n",
        "    \"\"\"\n",
        "    Agent-based RAG: Let the agent decide when to search and how to respond\n",
        "    \"\"\"\n",
        "    result = agent_executor.invoke({\"input\": query})\n",
        "    return result[\"output\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI9cEzCcNebq"
      },
      "outputs": [],
      "source": [
        "#assign experts for target\n",
        "def define_roles(definition_list):\n",
        "    global target_role_map\n",
        "    target_role_map = {\n",
        "        \"Local\": definition_list[1],\n",
        "        \"Expert\": definition_list[2],\n",
        "        \"User Analysis\": definition_list[3]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hk82xbOUfxny"
      },
      "outputs": [],
      "source": [
        "# Enhanced COLA framework function that incorporates answer type\n",
        "def add_predictions_sequential_enhanced(original_query, selected_intent, selected_answer_type, query_id):\n",
        "    global topic\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"Processing query {query_id}\")\n",
        "    print(f\"Original query: {original_query}\")\n",
        "    print(f\"Selected intent: {selected_intent}\")\n",
        "    print(f\"Selected answer type: {selected_answer_type}\")\n",
        "    print(\"---------DUAL INTENT CLARIFICATION COMPLETE--------\\n\")\n",
        "\n",
        "    # STEP 1: Rewrite query using both intents\n",
        "    working_query = rewrite_query_with_dual_intent(original_query, selected_intent, selected_answer_type)\n",
        "    print(f\"Rewritten query: {working_query}\")\n",
        "    print(\"---------QUERY REWRITING COMPLETE--------\\n\")\n",
        "\n",
        "    # STEP 2: Get roles and topic based on the rewritten query\n",
        "    definition_list = get_roles(working_query)\n",
        "    topic = definition_list[0]\n",
        "    define_roles(definition_list)\n",
        "\n",
        "    print(f\"Identified topic: {topic}\")\n",
        "    print(f\"Assigned roles: {definition_list[1:]}\")\n",
        "    print(\"---------ROLE ASSIGNMENT COMPLETE--------\\n\")\n",
        "\n",
        "    # STEP 3: Enhanced analysis functions that consider answer type\n",
        "    ling_response = local_analysis_enhanced(working_query, topic, selected_answer_type)\n",
        "    print(\"---------LOCAL RESPONSE--------\\n\")\n",
        "    print(ling_response)\n",
        "\n",
        "    expert_response = expert_analysis_enhanced(working_query, topic, selected_answer_type)\n",
        "    print(\"---------EXPERT RESPONSE--------\\n\")\n",
        "    print(expert_response)\n",
        "\n",
        "    user_response = user_analysis_enhanced(working_query, topic, selected_answer_type)\n",
        "    print(\"---------USER ANALYSIS RESPONSE--------\\n\")\n",
        "    print(user_response)\n",
        "\n",
        "    # STEP 4: Enhanced stance analysis\n",
        "    favor_response = stance_analysis_enhanced(working_query, ling_response, expert_response, user_response, topic, \"positive\", selected_answer_type)\n",
        "    print(\"---------IN FAVOR RESPONSE--------\\n\")\n",
        "    print(favor_response)\n",
        "\n",
        "    against_response = stance_analysis_enhanced(working_query, ling_response, expert_response, user_response, topic, \"negative\", selected_answer_type)\n",
        "    print(\"---------AGAINST RESPONSE--------\\n\")\n",
        "    print(against_response)\n",
        "\n",
        "    # STEP 5: Enhanced final judgement\n",
        "    final_response = final_judgement_enhanced(working_query, favor_response, against_response, topic, selected_answer_type)\n",
        "    print(\"---------ENHANCED COLA FRAMEWORK ANSWER--------\\n\")\n",
        "    print(final_response)\n",
        "\n",
        "    # Calculate processing time\n",
        "    end_time = time.time()\n",
        "    processing_time = round(end_time - start_time, 2)\n",
        "    print(f\"Total processing time: {processing_time} seconds\")\n",
        "\n",
        "    # Store results with all the information\n",
        "    results = {\n",
        "        'Rewritten_Query': working_query,  # Store the rewritten query\n",
        "        'Selected_Topic_Intent': selected_intent,  # Store topic selection\n",
        "        'Selected_Answer_Type': selected_answer_type,  # Store answer type selection\n",
        "        'Linguist Analysis': ling_response,\n",
        "        'Expert Analysis': expert_response,\n",
        "        'User Analysis': user_response,\n",
        "        'In Favor': favor_response,\n",
        "        'Against': against_response,\n",
        "        'Final Judgement': final_response,\n",
        "        'After RAG Agent': '',\n",
        "        'Final Plan': '',\n",
        "        'Processing_Time_Seconds': processing_time\n",
        "    }\n",
        "\n",
        "    update_query_results(query_id, results)\n",
        "    return str(final_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rc_R8RBINebr"
      },
      "outputs": [],
      "source": [
        "def get_last_query_data():\n",
        "    \"\"\"\n",
        "    Clean version - get the last query data from database\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not os.path.exists('cola_database.csv'):\n",
        "            return None, None, None\n",
        "\n",
        "        df = pd.read_csv('cola_database.csv')\n",
        "        if df.empty:\n",
        "            return None, None, None\n",
        "\n",
        "        # Try completed queries first, fallback to any query\n",
        "        completed_queries = df[df['Status'] == 'completed']\n",
        "        if not completed_queries.empty:\n",
        "            last_query = completed_queries.iloc[-1]\n",
        "        else:\n",
        "            last_query = df.iloc[-1]\n",
        "\n",
        "        query_id = int(last_query['ID'])\n",
        "        query = str(last_query['Query'])\n",
        "\n",
        "        # Handle different possible column names\n",
        "        if 'Final Judgement' in df.columns:\n",
        "            final_response = str(last_query['Final Judgement'])\n",
        "        elif 'Final_Judgement' in df.columns:\n",
        "            final_response = str(last_query['Final_Judgement'])\n",
        "        else:\n",
        "            final_response = query\n",
        "\n",
        "        return query_id, query, final_response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving last query data: {e}\")\n",
        "        return None, None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5K5zs__Nebr"
      },
      "outputs": [],
      "source": [
        "def final_response_rag(final_response, topic, query):\n",
        "    \"\"\"\n",
        "    Enhanced RAG prompt - more focused and concise\n",
        "    \"\"\"\n",
        "    response = f\"\"\"You are validating and enhancing an expert recommendation with current information.\n",
        "\n",
        "    USER'S QUERY: \"{query}\"\n",
        "    TOPIC: {topic}\n",
        "    EXPERT RECOMMENDATION: {final_response}\n",
        "\n",
        "    Your task:\n",
        "    1. Verify the recommendation against current information\n",
        "    2. Update any outdated details with recent data\n",
        "    3. Add missing important information\n",
        "    4. Enhance with specific, current details\n",
        "\n",
        "    Provide a refined recommendation that:\n",
        "    - Incorporates latest information\n",
        "    - Addresses the user's specific query\n",
        "    - Is practical and actionable\n",
        "    - Explains any significant updates made\n",
        "\n",
        "    Focus on improving the original recommendation, not creating a detailed plan.\"\"\"\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAFteMkLNebr"
      },
      "outputs": [],
      "source": [
        "def final_plan_rag(query_id, query, final_response):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Get topic from the database or global variable\n",
        "    global topic  # Make sure topic is accessible\n",
        "\n",
        "    print(f\"Starting RAG refinement for query: {query}\")\n",
        "    print(f\"Topic: {topic}\")\n",
        "    print(f\"Original COLA response: {final_response[:200]}...\")\n",
        "\n",
        "    # RAG - Generate enhanced prompt and get current information\n",
        "    prompt = final_response_rag(final_response, topic, query)\n",
        "    response = simple_rag_with_private_llm(prompt)\n",
        "    print(\"---------RAG ENHANCED RESPONSE--------\\n\")\n",
        "    print(response)\n",
        "\n",
        "    print(\"---------FINAL RAG REFINED ANSWER--------\\n\")\n",
        "    print(response)\n",
        "\n",
        "    # Calculate processing time\n",
        "    end_time = time.time()\n",
        "    processing_time = round(end_time - start_time, 2)\n",
        "    print(f\"Total processing time: {processing_time} seconds\")\n",
        "    # Debug: Check what we actually received\n",
        "    print(f\"DEBUG - query_id type: {type(query_id)}, value: {query_id}\")\n",
        "    print(f\"DEBUG - query type: {type(query)}, value: {query}\")\n",
        "\n",
        "    # Try to update database, but don't fail if it doesn't work\n",
        "    try:\n",
        "        results = {\n",
        "            'After RAG Agent': str(response),\n",
        "            'Final Plan': str(response),\n",
        "            'Processing_Time_Seconds_RAG': processing_time,\n",
        "        }\n",
        "        update_query_results(query_id, results)\n",
        "        print(f\"Database updated successfully for query ID {query_id}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Database update failed for query ID {query_id}: {e}\")\n",
        "        print(\"RAG completed successfully despite database update failure\")\n",
        "\n",
        "    return str(response)  # Return the RAG-enhanced response regardless of database status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgUxuS4aNebs"
      },
      "outputs": [],
      "source": [
        "def execute_rag_update(chatbot_history, state):\n",
        "    \"\"\"\n",
        "    Debug version to see what's happening\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\"DEBUG - execute_rag_update started\")\n",
        "\n",
        "        # Get the last query data\n",
        "        query_id, query, final_response = get_last_query_data()\n",
        "        print(f\"DEBUG - get_last_query_data returned: {query_id}, {query}, {final_response}\")\n",
        "\n",
        "        if not query_id:\n",
        "            print(\"DEBUG - No query_id found, returning error\")\n",
        "            error_msg = \"❌ No completed queries found in database. Please submit a query first.\"\n",
        "            new_message = {\"role\": \"assistant\", \"content\": error_msg}\n",
        "            updated_history = chatbot_history + [new_message]\n",
        "            updated_state = state + [new_message]\n",
        "            return updated_history, updated_state, \"\"\n",
        "\n",
        "        # Show processing message\n",
        "        processing_msg = f\"🔄 **Enhancing answer with current information...**\\n\\nOriginal query: '{query[:100]}...'\"\n",
        "        processing_message = {\"role\": \"assistant\", \"content\": processing_msg}\n",
        "        temp_history = chatbot_history + [processing_message]\n",
        "\n",
        "        yield temp_history, state, \"\"\n",
        "\n",
        "        print(\"DEBUG - About to call final_plan_rag\")\n",
        "        # Call RAG function\n",
        "        enhanced_response = final_plan_rag(query_id, query, final_response)\n",
        "        print(\"DEBUG - final_plan_rag completed\")\n",
        "\n",
        "        # Show enhanced result\n",
        "        success_msg = f\"✅ **Answer enhanced with current information!**\\n\\n{enhanced_response}\"\n",
        "        final_message = {\"role\": \"assistant\", \"content\": success_msg}\n",
        "\n",
        "        updated_history = chatbot_history + [final_message]\n",
        "        updated_state = state + [final_message]\n",
        "\n",
        "        yield updated_history, updated_state, \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"DEBUG - Exception in execute_rag_update: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        error_msg = f\"❌ **Error enhancing answer:** {str(e)}\"\n",
        "        error_message = {\"role\": \"assistant\", \"content\": error_msg}\n",
        "        updated_history = chatbot_history + [error_message]\n",
        "        updated_state = state + [error_message]\n",
        "        yield updated_history, updated_state, \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIQyIX3_9hDL"
      },
      "outputs": [],
      "source": [
        "def slow_echo_with_dual_intent_disambiguation(message, history):\n",
        "    global j\n",
        "    j += 1\n",
        "    current_id = j\n",
        "\n",
        "    # Add user message to history\n",
        "    history.append({\"role\": \"user\", \"content\": message})\n",
        "    yield history, history, \"\"\n",
        "\n",
        "    try:\n",
        "        # Step 1: Add query to database\n",
        "        add_new_query(current_id, message)\n",
        "\n",
        "        # Step 2: Generate topic intent options\n",
        "        topic_intent_options = generate_intent_options(message)\n",
        "        print(f\"Original: {message}\")\n",
        "        print(f\"Topic intent options: {topic_intent_options}\")\n",
        "\n",
        "        # Step 3: Show topic options to user\n",
        "        updated_history, updated_state = show_intent_options(history, history, topic_intent_options)\n",
        "        yield updated_history, updated_state, \"\"\n",
        "\n",
        "        # Store the options and query_id globally for button handlers\n",
        "        global current_intent_options, current_query_id, current_original_query, current_step\n",
        "        current_intent_options = topic_intent_options\n",
        "        current_query_id = current_id\n",
        "        current_original_query = message\n",
        "        current_step = \"topic_selection\"  # Track which step we're on\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"Error in intent disambiguation: {str(e)}\"\n",
        "        print(f\"Error: {e}\")\n",
        "        history[-1] = {\"role\": \"assistant\", \"content\": error_message}\n",
        "        yield history, history, \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_nUC3-eNebt"
      },
      "outputs": [],
      "source": [
        "# Global variables to store current session data\n",
        "current_intent_options = []\n",
        "current_query_id = None\n",
        "current_original_query = \"\"\n",
        "current_step = \"topic_selection\"  # Can be \"topic_selection\" or \"answer_type_selection\"\n",
        "current_answer_type_options = []\n",
        "current_selected_topic_intent = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5XHhQcWNebu"
      },
      "outputs": [],
      "source": [
        "def on_button_click():\n",
        "    return \"Button clicked!\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8Cx3_DTNebu"
      },
      "outputs": [],
      "source": [
        "def view_database_stats():\n",
        "    \"\"\"View database statistics\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv('cola_database.csv', dtype={\n",
        "            'ID': 'int64',\n",
        "            'Query': 'string',\n",
        "            'Linguist Analysis': 'string',\n",
        "            'Expert Analysis': 'string',\n",
        "            'User Analysis': 'string',\n",
        "            'In Favor': 'string',\n",
        "            'Against': 'string',\n",
        "            'Final Judgement': 'string',\n",
        "            'After RAG Agent': 'string',\n",
        "            'Final Plan': 'string',\n",
        "            'Processing_Time_Seconds': 'float64',\n",
        "            'Processing_Time_Seconds_RAG': 'float64',\n",
        "            'Timestamp': 'string',\n",
        "            'Status': 'string'\n",
        "        })\n",
        "\n",
        "        total_queries = len(df)\n",
        "        completed = len(df[df['Status'] == 'completed'])\n",
        "        pending = len(df[df['Status'] == 'pending'])\n",
        "        errors = len(df[df['Status'] == 'error'])\n",
        "\n",
        "        # Calculate average processing time for completed queries\n",
        "        completed_df = df[df['Status'] == 'completed']\n",
        "        if not completed_df.empty and 'Processing_Time_Seconds' in completed_df.columns:\n",
        "            # Filter out NaN values before calculating mean\n",
        "            processing_times = completed_df['Processing_Time_Seconds'].dropna()\n",
        "            if not processing_times.empty:\n",
        "                avg_time = processing_times.mean()\n",
        "                avg_time_str = f\"- Average processing time: {avg_time:.2f} seconds\"\n",
        "            else:\n",
        "                avg_time_str = \"- Average processing time: N/A\"\n",
        "        else:\n",
        "            avg_time_str = \"- Average processing time: N/A\"\n",
        "\n",
        "        stats = f\"\"\"\n",
        "        Database Statistics:\n",
        "        - Total queries: {total_queries}\n",
        "        - Completed: {completed}\n",
        "        - Pending: {pending}\n",
        "        - Errors: {errors}\n",
        "        {avg_time_str}\n",
        "\n",
        "        Recent queries:\n",
        "        \"\"\"\n",
        "\n",
        "        if not df.empty:\n",
        "            recent = df.tail(5)[['ID', 'Query', 'Status', 'Processing_Time_Seconds', 'Timestamp']]\n",
        "            stats += recent.to_string(index=False)\n",
        "\n",
        "        return stats\n",
        "    except Exception as e:\n",
        "        return f\"Error reading database: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0mOJ_VYNebu"
      },
      "outputs": [],
      "source": [
        "def handle_option_1_click_enhanced(chatbot_history, state):\n",
        "    global current_step, current_intent_options, current_answer_type_options, current_selected_topic_intent\n",
        "\n",
        "    if current_step == \"topic_selection\" and current_intent_options and len(current_intent_options) > 0:\n",
        "        # First step: topic selection\n",
        "        selected_topic = current_intent_options[0]\n",
        "        current_selected_topic_intent = selected_topic\n",
        "\n",
        "        # Generate answer type options\n",
        "        answer_type_options = generate_answer_type_options(current_original_query, selected_topic)\n",
        "        current_answer_type_options = answer_type_options\n",
        "        current_step = \"answer_type_selection\"\n",
        "\n",
        "        # Remove topic selection message and show answer type options\n",
        "        cleaned_history = chatbot_history[:-1] if chatbot_history else []\n",
        "        cleaned_state = state[:-1] if state else []\n",
        "\n",
        "        updated_history, updated_state = show_answer_type_options(cleaned_history, cleaned_state, answer_type_options)\n",
        "        yield updated_history, updated_state, \"\"\n",
        "\n",
        "    elif current_step == \"answer_type_selection\" and current_answer_type_options and len(current_answer_type_options) > 0:\n",
        "        # Second step: answer type selection\n",
        "        selected_answer_type = current_answer_type_options[0]\n",
        "\n",
        "        # Remove answer type selection message and process\n",
        "        cleaned_history = chatbot_history[:-1] if chatbot_history else []\n",
        "        cleaned_state = state[:-1] if state else []\n",
        "\n",
        "        yield from process_selected_answer_type(\n",
        "            selected_answer_type,\n",
        "            current_selected_topic_intent,\n",
        "            current_original_query,\n",
        "            current_query_id,\n",
        "            cleaned_history,\n",
        "            cleaned_state\n",
        "        )\n",
        "\n",
        "        # Reset step\n",
        "        current_step = \"topic_selection\"\n",
        "    else:\n",
        "        yield chatbot_history, state, \"\"\n",
        "\n",
        "def handle_option_2_click_enhanced(chatbot_history, state):\n",
        "    global current_step, current_intent_options, current_answer_type_options, current_selected_topic_intent\n",
        "\n",
        "    if current_step == \"topic_selection\" and current_intent_options and len(current_intent_options) > 1:\n",
        "        selected_topic = current_intent_options[1]\n",
        "        current_selected_topic_intent = selected_topic\n",
        "\n",
        "        answer_type_options = generate_answer_type_options(current_original_query, selected_topic)\n",
        "        current_answer_type_options = answer_type_options\n",
        "        current_step = \"answer_type_selection\"\n",
        "\n",
        "        cleaned_history = chatbot_history[:-1] if chatbot_history else []\n",
        "        cleaned_state = state[:-1] if state else []\n",
        "\n",
        "        updated_history, updated_state = show_answer_type_options(cleaned_history, cleaned_state, answer_type_options)\n",
        "        yield updated_history, updated_state, \"\"\n",
        "\n",
        "    elif current_step == \"answer_type_selection\" and current_answer_type_options and len(current_answer_type_options) > 1:\n",
        "        selected_answer_type = current_answer_type_options[1]\n",
        "\n",
        "        cleaned_history = chatbot_history[:-1] if chatbot_history else []\n",
        "        cleaned_state = state[:-1] if state else []\n",
        "\n",
        "        yield from process_selected_answer_type(\n",
        "            selected_answer_type,\n",
        "            current_selected_topic_intent,\n",
        "            current_original_query,\n",
        "            current_query_id,\n",
        "            cleaned_history,\n",
        "            cleaned_state\n",
        "        )\n",
        "\n",
        "        current_step = \"topic_selection\"\n",
        "    else:\n",
        "        yield chatbot_history, state, \"\"\n",
        "\n",
        "def handle_option_3_click_enhanced(chatbot_history, state):\n",
        "    global current_step, current_intent_options, current_answer_type_options, current_selected_topic_intent\n",
        "\n",
        "    if current_step == \"topic_selection\" and current_intent_options and len(current_intent_options) > 2:\n",
        "        selected_topic = current_intent_options[2]\n",
        "        current_selected_topic_intent = selected_topic\n",
        "\n",
        "        answer_type_options = generate_answer_type_options(current_original_query, selected_topic)\n",
        "        current_answer_type_options = answer_type_options\n",
        "        current_step = \"answer_type_selection\"\n",
        "\n",
        "        cleaned_history = chatbot_history[:-1] if chatbot_history else []\n",
        "        cleaned_state = state[:-1] if state else []\n",
        "\n",
        "        updated_history, updated_state = show_answer_type_options(cleaned_history, cleaned_state, answer_type_options)\n",
        "        yield updated_history, updated_state, \"\"\n",
        "\n",
        "    elif current_step == \"answer_type_selection\" and current_answer_type_options and len(current_answer_type_options) > 2:\n",
        "        selected_answer_type = current_answer_type_options[2]\n",
        "\n",
        "        cleaned_history = chatbot_history[:-1] if chatbot_history else []\n",
        "        cleaned_state = state[:-1] if state else []\n",
        "\n",
        "        yield from process_selected_answer_type(\n",
        "            selected_answer_type,\n",
        "            current_selected_topic_intent,\n",
        "            current_original_query,\n",
        "            current_query_id,\n",
        "            cleaned_history,\n",
        "            cleaned_state\n",
        "        )\n",
        "\n",
        "        current_step = \"topic_selection\"\n",
        "    else:\n",
        "        yield chatbot_history, state, \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-jp3lewNebv"
      },
      "outputs": [],
      "source": [
        "def create_enhanced_gradio_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        # Initialize database on startup\n",
        "        initialize_database()\n",
        "\n",
        "        chatbot = gr.Chatbot(\n",
        "            label=\"Enhanced Collaborative Search with Dual Intent Clarification\",\n",
        "            type=\"messages\",\n",
        "            height=400\n",
        "        )\n",
        "        msg = gr.Textbox(label=\"Your query\", placeholder=\"How can I help you today?\")\n",
        "        send_btn = gr.Button(\"Send\")\n",
        "\n",
        "        # Intent selection buttons (now handle both topic and answer type selection)\n",
        "        with gr.Row():\n",
        "            option1_btn = gr.Button(\"Option 1\", size=\"lg\", variant=\"secondary\")\n",
        "            option2_btn = gr.Button(\"Option 2\", size=\"lg\", variant=\"secondary\")\n",
        "            option3_btn = gr.Button(\"Option 3\", size=\"lg\", variant=\"secondary\")\n",
        "\n",
        "        extra_btn = gr.Button(\"Update information using RAG\")\n",
        "\n",
        "        # Database management buttons\n",
        "        with gr.Row():\n",
        "            stats_btn = gr.Button(\"View Database Stats\")\n",
        "            export_btn = gr.Button(\"Export Database\")\n",
        "\n",
        "        stats_output = gr.Textbox(label=\"Database Information\", lines=10)\n",
        "        state = gr.State([])\n",
        "\n",
        "        # Event handlers - REPLACE your existing handlers with these\n",
        "        send_btn.click(\n",
        "            slow_echo_with_dual_intent_disambiguation,\n",
        "            [msg, state],\n",
        "            [chatbot, state, msg]\n",
        "        )\n",
        "        msg.submit(\n",
        "            slow_echo_with_dual_intent_disambiguation,\n",
        "            [msg, state],\n",
        "            [chatbot, state, msg]\n",
        "        )\n",
        "\n",
        "        # Enhanced intent option handlers - REPLACE your existing button handlers\n",
        "        option1_btn.click(\n",
        "            handle_option_1_click_enhanced,\n",
        "            [chatbot, state],\n",
        "            [chatbot, state, msg]\n",
        "        )\n",
        "        option2_btn.click(\n",
        "            handle_option_2_click_enhanced,\n",
        "            [chatbot, state],\n",
        "            [chatbot, state, msg]\n",
        "        )\n",
        "        option3_btn.click(\n",
        "            handle_option_3_click_enhanced,\n",
        "            [chatbot, state],\n",
        "            [chatbot, state, msg]\n",
        "        )\n",
        "\n",
        "        # Keep your existing handlers\n",
        "        extra_btn.click(execute_rag_update, [chatbot, state], [chatbot, state, msg])\n",
        "        stats_btn.click(view_database_stats, outputs=stats_output)\n",
        "\n",
        "        # Keep your existing launcher\n",
        "        demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xp8e3VZzNebw",
        "outputId": "57447d1e-e29e-4e7a-c5b2-986df3cb67fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enhanced COLA database initialized\n",
            "* Running on local URL:  http://127.0.0.1:7864\n",
            "* Running on public URL: https://3da7a7b5d897f66065.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://3da7a7b5d897f66065.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added query 1 to enhanced COLA database\n",
            "Original: I want to know more about Panama\n",
            "Topic intent options: ['Panama (country in Central America)', 'Panama (hat style)', 'Panama (canal and transportation hub)']\n",
            "Processing query 1\n",
            "Original query: I want to know more about Panama\n",
            "Selected intent: Panama (country in Central America)\n",
            "Selected answer type: Basic Overview (simple introduction for beginners)\n",
            "---------DUAL INTENT CLARIFICATION COMPLETE--------\n",
            "\n",
            "Rewritten query: Provide a basic overview and introduction to Panama, a country in Central America, covering its key features, geography, culture, and essential information for beginners.\n",
            "---------QUERY REWRITING COMPLETE--------\n",
            "\n",
            "Identified topic: [\n",
            "Assigned roles: \"Introduction to Panama\", \"Geographer\", \"Cultural Anthropologist\", \"Travel Consultant\"]\n",
            "---------ROLE ASSIGNMENT COMPLETE--------\n",
            "\n",
            "---------LOCAL RESPONSE--------\n",
            "\n",
            "BASIC OVERVIEW:\n",
            "\n",
            "Panama is a country located in Central America, connecting North America to South America. Here are the key features and essential information you need to know:\n",
            "\n",
            "**Geography:**\n",
            "Panama is a narrow country, bordered by Costa Rica to the west and Colombia to the east. It has a long coastline along the Pacific Ocean to the south and the Caribbean Sea to the north. The country is home to mountains, forests, and coastal plains.\n",
            "\n",
            "**Capital City:**\n",
            "The capital city of Panama is Panama City, a bustling metropolis with a mix of modern and historic architecture.\n",
            "\n",
            "**Culture:**\n",
            "Panamanian culture is a blend of Spanish, African, and indigenous influences. The country is known for its vibrant music, dance, and festivals, such as the Panama Jazz Festival and the Boquete Flower and Coffee Fair.\n",
            "\n",
            "**Language:**\n",
            "The official language of Panama is Spanish, but many Panamanians also speak English, especially in tourist areas and business settings.\n",
            "\n",
            "**Currency:**\n",
            "The official currency of Panama is the US dollar, making it easy for American tourists to visit and travel within the country.\n",
            "\n",
            "**Key Attractions:**\n",
            "Some of the top attractions in Panama include the Panama Canal, a famous waterway that connects the Atlantic and Pacific Oceans, as well as the Gamboa Rainforest Reserve, the San Blas Islands, and the historic Casco Viejo neighborhood in Panama City.\n",
            "\n",
            "**Essential Information:**\n",
            "Panama is a popular destination for tourists, with a growing economy and a high standard of living. The country has a tropical climate, with two main seasons: dry and rainy. Visitors can enjoy a range of outdoor activities, such as hiking, surfing, and snorkeling, as well as exploring the country's rich history and culture.\n",
            "\n",
            "Overall, Panama is a unique and fascinating country that offers a mix of natural beauty, cultural richness, and modern amenities, making it an exciting destination for beginners to explore.\n",
            "---------EXPERT RESPONSE--------\n",
            "\n",
            "BASIC OVERVIEW:\n",
            "\n",
            "**Introduction to Panama**\n",
            "\n",
            "Panama is a country located in Central America, connecting North America to South America. It's a narrow strip of land with a unique geography, rich culture, and exciting history. Here's a beginner's guide to get you started:\n",
            "\n",
            "**Key Features:**\n",
            "\n",
            "1. **Location**: Panama is situated in Central America, bordered by Costa Rica to the west, Colombia to the east, the Caribbean Sea to the north, and the Pacific Ocean to the south.\n",
            "2. **Capital City**: The capital and largest city is Panama City, a bustling metropolis with a mix of modern and historic architecture.\n",
            "3. **Language**: The official language is Spanish, but many Panamanians also speak English, especially in tourist areas.\n",
            "4. **Currency**: The Panamanian balboa is the local currency, but the US dollar is widely accepted.\n",
            "\n",
            "**Geography:**\n",
            "\n",
            "1. **Isthmus**: Panama is an isthmus, a narrow piece of land that connects two larger landmasses.\n",
            "2. **Mountains**: The country has a mountainous region, with the highest peak being Volcán Barú, which offers stunning views and hiking opportunities.\n",
            "3. **Canals**: The famous Panama Canal, one of the world's most important waterways, runs through the country, connecting the Atlantic and Pacific Oceans.\n",
            "4. **Beaches**: Panama has a long coastline with beautiful beaches, coral reefs, and islands, perfect for swimming, snorkeling, and surfing.\n",
            "\n",
            "**Culture:**\n",
            "\n",
            "1. **Diverse Heritage**: Panama has a rich cultural heritage, with influences from indigenous, Spanish, African, and American traditions.\n",
            "2. **Music and Dance**: Traditional music and dance, such as salsa and reggaeton, are popular, and you can experience them in local festivals and events.\n",
            "3. **Cuisine**: Panamanian cuisine is a fusion of flavors, with popular dishes like sancocho (a hearty stew), arroz con pollo (chicken and rice), and fresh seafood.\n",
            "4. **Friendly People**: Panamanians are known for their warm hospitality and welcoming nature, making visitors feel at home.\n",
            "\n",
            "**Essential Information:**\n",
            "\n",
            "1. **Climate**: Panama has a tropical climate, with two main seasons: dry (December to April) and rainy (May to November).\n",
            "2. **Safety**: As with any country, take normal precautions to ensure your safety, such as being aware of your surroundings and keeping valuables secure.\n",
            "3. **Getting Around**: Panama has a well-developed transportation system, with airports, buses, and taxis making it easy to explore the country.\n",
            "4. **Tourist Attractions**: Visit the Panama Canal, explore the historic Casco Viejo neighborhood, and enjoy the beautiful beaches and nature reserves.\n",
            "\n",
            "This introduction provides a solid foundation for beginners to understand the basics of Panama, its geography, culture, and essential information to plan a trip or learn more about this fascinating country.\n",
            "---------USER ANALYSIS RESPONSE--------\n",
            "\n",
            "BASIC OVERVIEW:\n",
            "\n",
            "**Introduction to Panama**\n",
            "\n",
            "Panama is a country located in Central America, connecting North America to South America. It's a narrow strip of land with a unique shape, bordered by Costa Rica to the west, Colombia to the east, the Caribbean Sea to the north, and the Pacific Ocean to the south.\n",
            "\n",
            "**Key Features:**\n",
            "\n",
            "* Capital city: Panama City\n",
            "* Population: around 4.3 million people\n",
            "* Language: Spanish (official), but many people also speak English\n",
            "* Currency: US dollar (official)\n",
            "\n",
            "**Geography:**\n",
            "\n",
            "* Panama is a tropical country with a mix of mountains, forests, and coastlines\n",
            "* The Panama Canal, one of the world's most important waterways, runs through the country\n",
            "* The country has a diverse range of wildlife, including monkeys, sloths, and toucans\n",
            "\n",
            "**Culture:**\n",
            "\n",
            "* Panamanian culture is a blend of Spanish, African, and indigenous influences\n",
            "* Music and dance are important parts of Panamanian culture, with popular styles like salsa and reggaeton\n",
            "* The country celebrates many festivals and holidays, including Carnaval and Independence Day\n",
            "\n",
            "**Essential Information:**\n",
            "\n",
            "* Panama is a popular tourist destination, with many beautiful beaches, islands, and national parks to explore\n",
            "* The country has a growing economy, with a mix of industries like banking, logistics, and tourism\n",
            "* Panama is a safe country to visit, with low crime rates compared to other countries in the region\n",
            "\n",
            "Overall, Panama is a fascinating country with a rich culture, stunning natural beauty, and a unique history. Whether you're interested in exploring the outdoors, learning about the country's history, or simply enjoying the local cuisine, Panama has something to offer for everyone.\n",
            "---------IN FAVOR RESPONSE--------\n",
            "\n",
            "**BASIC OVERVIEW: Introduction to Panama**\n",
            "\n",
            "Panama is a country located in Central America, connecting North America to South America. It's a narrow strip of land with a unique geography, rich culture, and exciting history. Here's a beginner's guide to get you started:\n",
            "\n",
            "**Key Features:**\n",
            "\n",
            "1. **Location**: Panama is situated in Central America, bordered by Costa Rica to the west, Colombia to the east, the Caribbean Sea to the north, and the Pacific Ocean to the south.\n",
            "2. **Capital City**: The capital and largest city is Panama City, a bustling metropolis with a mix of modern and historic architecture.\n",
            "3. **Language**: The official language is Spanish, but many Panamanians also speak English, especially in tourist areas.\n",
            "4. **Currency**: The US dollar is widely accepted, making it easy for American tourists to visit and travel within the country.\n",
            "\n",
            "**Geography and Culture:**\n",
            "\n",
            "* Panama is home to mountains, forests, and coastal plains, offering a diverse range of landscapes and outdoor activities.\n",
            "* The country has a rich cultural heritage, with influences from indigenous, Spanish, African, and American traditions.\n",
            "* Traditional music and dance, such as salsa and reggaeton, are popular, and you can experience them in local festivals and events.\n",
            "\n",
            "**Essential Information:**\n",
            "\n",
            "1. **Climate**: Panama has a tropical climate, with two main seasons: dry (December to April) and rainy (May to November).\n",
            "2. **Safety**: Panama is a safe country to visit, with low crime rates compared to other countries in the region.\n",
            "3. **Tourist Attractions**: Visit the Panama Canal, explore the historic Casco Viejo neighborhood, and enjoy the beautiful beaches and nature reserves.\n",
            "\n",
            "**Why Panama is a Great Destination:**\n",
            "\n",
            "* According to Expert I, Panama has a \"unique and fascinating country that offers a mix of natural beauty, cultural richness, and modern amenities.\"\n",
            "* Expert n notes that Panama is a \"popular tourist destination, with many beautiful beaches, islands, and national parks to explore.\"\n",
            "* Expert : highlights the country's \"growing economy, with a mix of industries like banking, logistics, and tourism.\"\n",
            "\n",
            "Overall, Panama is a fantastic country to visit or learn about, with its rich culture, stunning natural beauty, and unique history. Whether you're interested in exploring the outdoors, learning about the country's history, or simply enjoying the local cuisine, Panama has something to offer for everyone.\n",
            "---------AGAINST RESPONSE--------\n",
            "\n",
            "**BASIC OVERVIEW: A Critical Introduction to Panama**\n",
            "\n",
            "As a beginner, it's essential to approach information about Panama with a critical eye. While the country may seem like an exciting destination, there are several concerns and potential issues that need to be addressed. This overview will highlight some of the problematic aspects of Panama, using evidence from expert analyses.\n",
            "\n",
            "**Geography: A Limited Perspective**\n",
            "\n",
            "Expert I mentions that Panama is a narrow strip of land with a unique geography, but fails to discuss the potential drawbacks of this geography. For example, the country's narrow shape can make it prone to natural disasters like earthquakes and landslides. Additionally, Expert n notes that Panama is a tropical country with a mix of mountains, forests, and coastlines, but doesn't mention the deforestation and environmental degradation that have occurred in these areas.\n",
            "\n",
            "**Culture: A Superficial Representation**\n",
            "\n",
            "Expert analyses often portray Panamanian culture as a vibrant and diverse blend of influences. However, this representation can be superficial and overlook the complexities of the country's cultural identity. For instance, Expert I mentions that traditional music and dance are popular, but doesn't discuss the potential cultural appropriation and exploitation of these traditions. Moreover, Expert n notes that the country celebrates many festivals and holidays, but fails to mention the commercialization and touristification of these events.\n",
            "\n",
            "**Essential Information: A Lack of Critical Context**\n",
            "\n",
            "The expert analyses often provide essential information about Panama, such as its population, language, and currency. However, this information is often presented without critical context. For example, Expert I mentions that the US dollar is widely accepted, but doesn't discuss the potential economic implications of using a foreign currency. Additionally, Expert n notes that Panama is a safe country to visit, but doesn't provide any evidence to support this claim or discuss the potential risks and precautions that visitors should take.\n",
            "\n",
            "**Key Concerns: A Beginner's Warning**\n",
            "\n",
            "As a beginner, it's crucial to be aware of the potential concerns and risks associated with Panama. These include:\n",
            "\n",
            "* Environmental degradation and deforestation\n",
            "* Cultural appropriation and exploitation\n",
            "* Economic instability and dependence on foreign currency\n",
            "* Safety risks and lack of critical context\n",
            "\n",
            "In conclusion, while Panama may seem like an exciting destination, it's essential to approach information about the country with a critical eye. By examining the expert analyses through a negative lens, we can identify potential concerns and risks that need to be addressed. As a beginner, it's crucial to be aware of these issues and approach your exploration of Panama with caution and critical thinking.\n",
            "---------ENHANCED COLA FRAMEWORK ANSWER--------\n",
            "\n",
            "**BASIC OVERVIEW: Introduction to Panama**\n",
            "\n",
            "Panama is a country located in Central America, connecting North America to South America. It's a narrow strip of land with a unique geography, rich culture, and exciting history. Here's a beginner's guide to get you started:\n",
            "\n",
            "**Key Features:**\n",
            "\n",
            "1. **Location**: Panama is situated in Central America, bordered by Costa Rica to the west, Colombia to the east, the Caribbean Sea to the north, and the Pacific Ocean to the south.\n",
            "2. **Capital City**: The capital and largest city is Panama City, a bustling metropolis with a mix of modern and historic architecture.\n",
            "3. **Language**: The official language is Spanish, but many Panamanians also speak English, especially in tourist areas.\n",
            "4. **Currency**: The US dollar is widely accepted, making it easy for American tourists to visit and travel within the country.\n",
            "\n",
            "**Geography and Culture:**\n",
            "\n",
            "* Panama is home to mountains, forests, and coastal plains, offering a diverse range of landscapes and outdoor activities.\n",
            "* The country has a rich cultural heritage, with influences from indigenous, Spanish, African, and American traditions.\n",
            "* Traditional music and dance, such as salsa and reggaeton, are popular, and you can experience them in local festivals and events.\n",
            "\n",
            "**Essential Information:**\n",
            "\n",
            "1. **Climate**: Panama has a tropical climate, with two main seasons: dry (December to April) and rainy (May to November).\n",
            "2. **Safety**: Panama is generally a safe country to visit, with low crime rates compared to other countries in the region. However, as with any travel destination, it's essential to take normal precautions to ensure your safety.\n",
            "3. **Tourist Attractions**: Visit the Panama Canal, explore the historic Casco Viejo neighborhood, and enjoy the beautiful beaches and nature reserves.\n",
            "\n",
            "**Important Considerations:**\n",
            "\n",
            "* Panama is working to address environmental concerns, such as deforestation and pollution, so it's essential to be mindful of your impact on the environment during your visit.\n",
            "* The country is also home to a diverse cultural landscape, and it's crucial to be respectful of local customs and traditions.\n",
            "* While Panama is generally safe, it's always a good idea to stay informed about local conditions and take necessary precautions to ensure your safety.\n",
            "\n",
            "**Why Panama is a Great Destination:**\n",
            "\n",
            "Panama offers a unique blend of natural beauty, cultural richness, and modern amenities, making it an exciting destination for travelers. With its growing economy, rich history, and stunning landscapes, Panama has something to offer for everyone. Whether you're interested in exploring the outdoors, learning about the country's history, or simply enjoying the local cuisine, Panama is a great choice for your next adventure.\n",
            "Total processing time: 185.24 seconds\n",
            "Updated all results for query 1\n",
            "DEBUG - execute_rag_update started\n",
            "Error retrieving last query data: 'Query'\n",
            "DEBUG - get_last_query_data returned: None, None, None\n",
            "DEBUG - No query_id found, returning error\n"
          ]
        }
      ],
      "source": [
        "create_enhanced_gradio_interface()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOAtdNiONebx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}