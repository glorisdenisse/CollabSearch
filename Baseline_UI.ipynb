{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Installing Gardio Library"
      ],
      "metadata": {
        "id": "9L3Tpt23JS3B"
      },
      "id": "9L3Tpt23JS3B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a09cc69-0015-4b2c-a6ed-8e17159bb73b",
      "metadata": {
        "id": "1a09cc69-0015-4b2c-a6ed-8e17159bb73b",
        "outputId": "f37f6ead-239c-49b9-f603-264502125efb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: The directory '/mnt/primary/launcher-cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: gradio in /opt/miniconda3/lib/python3.10/site-packages (5.42.0)\n",
            "Requirement already satisfied: openai in /opt/miniconda3/lib/python3.10/site-packages (1.99.9)\n",
            "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.10/site-packages (2.2.3)\n",
            "Requirement already satisfied: openpyxl in /opt/miniconda3/lib/python3.10/site-packages (3.1.5)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.1 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (1.11.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.12.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /opt/miniconda3/lib/python3.10/site-packages (from gradio-client==1.11.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /opt/miniconda3/lib/python3.10/site-packages (from gradio-client==1.11.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (1.8.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /opt/miniconda3/lib/python3.10/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /opt/miniconda3/lib/python3.10/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /opt/miniconda3/lib/python3.10/site-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/miniconda3/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /opt/miniconda3/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
            "Requirement already satisfied: certifi in /opt/miniconda3/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /opt/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /opt/miniconda3/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/miniconda3/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /opt/miniconda3/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /opt/miniconda3/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /opt/miniconda3/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniconda3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.0.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (1.26.18)\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/miniconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install gradio openai pandas openpyxl"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries"
      ],
      "metadata": {
        "id": "rIxJJ2ZxJepJ"
      },
      "id": "rIxJJ2ZxJepJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e33ef92e-6fd6-4eda-97d5-7b0b4a9ece6f",
      "metadata": {
        "id": "e33ef92e-6fd6-4eda-97d5-7b0b4a9ece6f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Set Environmental Variables"
      ],
      "metadata": {
        "id": "CkpDm0ZFJgbi"
      },
      "id": "CkpDm0ZFJgbi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up your API key\n",
        "os.environ[\"IDA_LLM_API_KEY\"] = \"your key here\"\n",
        "\n",
        "# Initialize your private LLM client\n",
        "client = OpenAI(\n",
        "    base_url=\"http://api.llm.apps.os.dcs.gla.ac.uk/v1\",\n",
        "    api_key=os.environ['IDA_LLM_API_KEY']\n",
        ")"
      ],
      "metadata": {
        "id": "f4kWywl0JdVo"
      },
      "id": "f4kWywl0JdVo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Database Initialization"
      ],
      "metadata": {
        "id": "zC77XSl3JnwK"
      },
      "id": "zC77XSl3JnwK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1bdce23-f1cf-4d4e-a82f-0b46b1b0d8cf",
      "metadata": {
        "id": "b1bdce23-f1cf-4d4e-a82f-0b46b1b0d8cf"
      },
      "outputs": [],
      "source": [
        "def initialize_excel_database():\n",
        "    '''\n",
        "    Initialize Excel database file for storing chat interaction logs and metrics.\n",
        "    Creates new Excel file with structured columns for timestamps, queries, responses, and performance data if not exists.\n",
        "    '''\n",
        "    filename = \"chat_interactions.xlsx\"\n",
        "\n",
        "    if not os.path.exists(filename):\n",
        "        # Create new Excel file with proper columns\n",
        "        df = pd.DataFrame(columns=[\n",
        "            'Timestamp',\n",
        "            'Session_ID',\n",
        "            'User_Query',\n",
        "            'AI_Response',\n",
        "            'Response_Time_Seconds',\n",
        "            'Query_Length',\n",
        "            'Response_Length'\n",
        "        ])\n",
        "        df.to_excel(filename, index=False, engine='openpyxl')\n",
        "        print(f\"✅ Created new Excel database: {filename}\")\n",
        "    else:\n",
        "        print(f\"✅ Excel database exists: {filename}\")\n",
        "\n",
        "    return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be2c8914-f30c-49bc-9303-4b3b7c875048",
      "metadata": {
        "id": "be2c8914-f30c-49bc-9303-4b3b7c875048"
      },
      "outputs": [],
      "source": [
        "def save_interaction_to_excel(user_query, ai_response, response_time, session_id=None):\n",
        "    '''\n",
        "    Save chat interaction data to Excel file with timestamp, query/response metrics, and session tracking.\n",
        "    Appends new interaction row to existing Excel database, handles file creation/reading errors, tracks conversation analytics.\n",
        "    '''\n",
        "    try:\n",
        "        filename = \"chat_interactions.xlsx\"\n",
        "\n",
        "        # Create new row data\n",
        "        new_row = {\n",
        "            'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'Session_ID': session_id or f\"session_{int(time.time())}\",\n",
        "            'User_Query': user_query,\n",
        "            'AI_Response': ai_response,\n",
        "            'Response_Time_Seconds': round(response_time, 2),\n",
        "            'Query_Length': len(user_query),\n",
        "            'Response_Length': len(ai_response)\n",
        "        }\n",
        "\n",
        "        # Read existing data or create new DataFrame\n",
        "        if os.path.exists(filename):\n",
        "            try:\n",
        "                df = pd.read_excel(filename, engine='openpyxl')\n",
        "                # Append new row using loc to avoid FutureWarning\n",
        "                df.loc[len(df)] = new_row\n",
        "            except Exception as read_error:\n",
        "                print(f\"Warning: Could not read existing file ({read_error}), creating new one\")\n",
        "                df = pd.DataFrame([new_row])\n",
        "        else:\n",
        "            # Create new DataFrame with first row\n",
        "            df = pd.DataFrame([new_row])\n",
        "\n",
        "        # Save to Excel\n",
        "        df.to_excel(filename, index=False, engine='openpyxl')\n",
        "        print(f\"💾 Saved interaction to {filename} (Total rows: {len(df)})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error saving to Excel: {e}\")\n",
        "        # Don't let Excel errors break the chat\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Llama Interactions"
      ],
      "metadata": {
        "id": "ZLsy8q2dKD4j"
      },
      "id": "ZLsy8q2dKD4j"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40b74de7-5313-4b33-af9a-c5ac3da16294",
      "metadata": {
        "id": "40b74de7-5313-4b33-af9a-c5ac3da16294"
      },
      "outputs": [],
      "source": [
        "def get_llm_response(prompt, max_retries=3):\n",
        "    '''\n",
        "    Get response from private Llama-3-8B model with retry logic and error handling.\n",
        "    Attempts multiple requests with 2-second delays between retries, returns graceful error message if all attempts fail.\n",
        "    '''\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"llama-3-8b-instruct\",\n",
        "                messages=messages,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(2)  # Wait before retry\n",
        "                print(f\"Attempt {attempt + 1} failed: {e}. Retrying...\")\n",
        "            else:\n",
        "                print(f\"All attempts failed. Error: {e}\")\n",
        "                return f\"Sorry, I'm having trouble connecting to the AI service. Error: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a15a2bfb-a164-4eff-8476-c603567317cc",
      "metadata": {
        "id": "a15a2bfb-a164-4eff-8476-c603567317cc"
      },
      "outputs": [],
      "source": [
        "def chat_with_llm(user_input, chat_history, session_state):\n",
        "    '''\n",
        "    Handle complete chat interaction flow with LLM including session management, response timing, and Excel logging.\n",
        "    Manages chat history, generates session IDs, calls LLM with error handling, saves all interactions and errors to Excel database.\n",
        "    '''\n",
        "    if not user_input.strip():\n",
        "        return chat_history, \"\", session_state\n",
        "\n",
        "    # Generate session ID if not exists\n",
        "    if not session_state.get(\"session_id\"):\n",
        "        session_state[\"session_id\"] = f\"session_{int(time.time())}\"\n",
        "\n",
        "    # Add user message to history\n",
        "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Get LLM response with timing\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        ai_response = get_llm_response(user_input)\n",
        "        response_time = time.time() - start_time\n",
        "\n",
        "        # Add AI response to history\n",
        "        chat_history.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "\n",
        "        # Save to Excel\n",
        "        save_interaction_to_excel(\n",
        "            user_query=user_input,\n",
        "            ai_response=ai_response,\n",
        "            response_time=response_time,\n",
        "            session_id=session_state[\"session_id\"]\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        response_time = time.time() - start_time\n",
        "        error_message = f\"Error: {str(e)}\"\n",
        "        chat_history.append({\"role\": \"assistant\", \"content\": error_message})\n",
        "\n",
        "        # Save error to Excel too\n",
        "        save_interaction_to_excel(\n",
        "            user_query=user_input,\n",
        "            ai_response=error_message,\n",
        "            response_time=response_time,\n",
        "            session_id=session_state[\"session_id\"]\n",
        "        )\n",
        "\n",
        "    return chat_history, \"\", session_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "736ac881-43e6-4ed7-9492-c2bb406090a3",
      "metadata": {
        "id": "736ac881-43e6-4ed7-9492-c2bb406090a3"
      },
      "outputs": [],
      "source": [
        "def clear_chat(session_state):\n",
        "    \"\"\"Clear the chat history but keep session info\"\"\"\n",
        "    return [], \"\", session_state\n",
        "\n",
        "def test_connection():\n",
        "    \"\"\"Test the LLM connection\"\"\"\n",
        "    try:\n",
        "        test_response = get_llm_response(\"Hello, can you confirm you're working?\")\n",
        "        return f\"✅ Connection successful! Response: {test_response[:100]}...\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ Connection failed: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "290e01aa-90a1-492b-b82e-923af39b8d0b",
      "metadata": {
        "id": "290e01aa-90a1-492b-b82e-923af39b8d0b"
      },
      "outputs": [],
      "source": [
        "def view_excel_stats():\n",
        "    \"\"\"\n",
        "    View statistics from the Excel database\n",
        "    \"\"\"\n",
        "    try:\n",
        "        filename = \"chat_interactions.xlsx\"\n",
        "        if not os.path.exists(filename):\n",
        "            return \"📊 No chat data found. Start chatting to see statistics!\"\n",
        "\n",
        "        df = pd.read_excel(filename, engine='openpyxl')\n",
        "\n",
        "        if df.empty:\n",
        "            return \"📊 No interactions recorded yet.\"\n",
        "\n",
        "        total_interactions = len(df)\n",
        "        unique_sessions = df['Session_ID'].nunique() if 'Session_ID' in df.columns else 0\n",
        "        avg_response_time = df['Response_Time_Seconds'].mean() if 'Response_Time_Seconds' in df.columns else 0\n",
        "        avg_query_length = df['Query_Length'].mean() if 'Query_Length' in df.columns else 0\n",
        "\n",
        "        # Recent interactions\n",
        "        recent = df.tail(5)[['Timestamp', 'User_Query', 'Response_Time_Seconds']].copy()\n",
        "        recent['User_Query'] = recent['User_Query'].apply(\n",
        "            lambda x: str(x)[:50] + '...' if len(str(x)) > 50 else str(x)\n",
        "        )\n",
        "\n",
        "        stats = f\"\"\"📊 **Chat Database Statistics**\n",
        "\n",
        "**Overall Stats:**\n",
        "- Total Interactions: {total_interactions}\n",
        "- Unique Sessions: {unique_sessions}\n",
        "- Average Response Time: {avg_response_time:.2f} seconds\n",
        "- Average Query Length: {avg_query_length:.0f} characters\n",
        "\n",
        "**Recent Interactions:**\n",
        "{recent.to_string(index=False)}\n",
        "\n",
        "**File Location:** {os.path.abspath(filename)}\n",
        "        \"\"\"\n",
        "\n",
        "        return stats\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error reading Excel database: {e}\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#UI MAIN"
      ],
      "metadata": {
        "id": "VKVi9THCKLsp"
      },
      "id": "VKVi9THCKLsp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a65dfb62-a0d6-4d88-aeba-8ea4102c7776",
      "metadata": {
        "id": "a65dfb62-a0d6-4d88-aeba-8ea4102c7776"
      },
      "outputs": [],
      "source": [
        "def create_basic_interface():\n",
        "  '''\n",
        "  Create simple Gradio chat interface with Excel logging for basic LLM interactions.\n",
        "  Initializes Excel database, provides chat UI with send/clear functions, connection testing, stats viewing, and example prompts.\n",
        "  '''\n",
        "    # Initialize Excel database\n",
        "    initialize_excel_database()\n",
        "\n",
        "    with gr.Blocks(title=\"Basic LLM Chat Interface\") as demo:\n",
        "\n",
        "        gr.Markdown(\"# 🤖 Basic LLM Chat Interface\")\n",
        "        gr.Markdown(\"Simple chat interface using your private LLM server with Excel logging\")\n",
        "\n",
        "        # Session state to track user sessions\n",
        "        session_state = gr.State({\"session_id\": None})\n",
        "\n",
        "        # Chat interface\n",
        "        chatbot = gr.Chatbot(\n",
        "            label=\"Chat with AI\",\n",
        "            type=\"messages\",\n",
        "            height=400,\n",
        "            show_label=True\n",
        "        )\n",
        "\n",
        "        # Input area\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=4):\n",
        "                msg = gr.Textbox(\n",
        "                    label=\"Your message\",\n",
        "                    placeholder=\"Type your message here...\",\n",
        "                    lines=2,\n",
        "                    max_lines=5\n",
        "                )\n",
        "            with gr.Column(scale=1):\n",
        "                send_btn = gr.Button(\"🚀 Send\", variant=\"primary\", size=\"lg\")\n",
        "                clear_btn = gr.Button(\"🗑️ Clear Chat\", variant=\"secondary\")\n",
        "\n",
        "        # Management area\n",
        "        with gr.Row():\n",
        "            test_btn = gr.Button(\"🔧 Test Connection\")\n",
        "            stats_btn = gr.Button(\"📊 View Excel Stats\")\n",
        "\n",
        "        with gr.Row():\n",
        "            connection_status = gr.Textbox(\n",
        "                label=\"Connection Status\",\n",
        "                interactive=False,\n",
        "                lines=2\n",
        "            )\n",
        "            excel_stats = gr.Textbox(\n",
        "                label=\"Excel Database Stats\",\n",
        "                interactive=False,\n",
        "                lines=10,\n",
        "                visible=False\n",
        "            )\n",
        "\n",
        "        # Event handlers\n",
        "        def handle_submit(user_input, history, session):\n",
        "            return chat_with_llm(user_input, history, session)\n",
        "\n",
        "        def handle_clear(session):\n",
        "            return clear_chat(session)\n",
        "\n",
        "        # Send button click\n",
        "        send_btn.click(\n",
        "            handle_submit,\n",
        "            inputs=[msg, chatbot, session_state],\n",
        "            outputs=[chatbot, msg, session_state]\n",
        "        )\n",
        "\n",
        "        # Enter key press\n",
        "        msg.submit(\n",
        "            handle_submit,\n",
        "            inputs=[msg, chatbot, session_state],\n",
        "            outputs=[chatbot, msg, session_state]\n",
        "        )\n",
        "\n",
        "        # Clear button\n",
        "        clear_btn.click(\n",
        "            handle_clear,\n",
        "            inputs=[session_state],\n",
        "            outputs=[chatbot, msg, session_state]\n",
        "        )\n",
        "\n",
        "        # Test connection\n",
        "        test_btn.click(\n",
        "            test_connection,\n",
        "            outputs=[connection_status]\n",
        "        )\n",
        "\n",
        "        # View Excel stats\n",
        "        def show_stats():\n",
        "            stats = view_excel_stats()\n",
        "            return gr.update(visible=True), stats\n",
        "\n",
        "        stats_btn.click(\n",
        "            show_stats,\n",
        "            outputs=[excel_stats, excel_stats]\n",
        "        )\n",
        "\n",
        "        # Examples\n",
        "        gr.Examples(\n",
        "            examples=[\n",
        "                [\"Hello! How are you today?\"],\n",
        "                [\"Can you explain quantum computing in simple terms?\"],\n",
        "                [\"Write a short poem about programming\"],\n",
        "                [\"What's the capital of France?\"],\n",
        "                [\"Help me understand machine learning\"]\n",
        "            ],\n",
        "            inputs=[msg]\n",
        "        )\n",
        "\n",
        "    return demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c5a68ad-a21b-4923-a22a-67de0872e142",
      "metadata": {
        "id": "7c5a68ad-a21b-4923-a22a-67de0872e142",
        "outputId": "bfa3c9ab-97fe-4880-9322-9b880fd0dd79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Testing LLM connection...\n",
            "Testing LLM connection...\n",
            "LLM Response: Hello! It's nice to meet you!\n",
            "✅ LLM connection successful!\n",
            "📊 Initializing Excel database...\n",
            "✅ Created new Excel database: chat_interactions.xlsx\n",
            "🚀 Starting Gradio interface...\n",
            "✅ Excel database exists: chat_interactions.xlsx\n",
            "* Running on local URL:  http://127.0.0.1:7874\n",
            "* Running on public URL: https://670ebae4b9d06494aa.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://670ebae4b9d06494aa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💾 Saved interaction to chat_interactions.xlsx (Total rows: 1)\n",
            "💾 Saved interaction to chat_interactions.xlsx (Total rows: 2)\n",
            "💾 Saved interaction to chat_interactions.xlsx (Total rows: 3)\n",
            "💾 Saved interaction to chat_interactions.xlsx (Total rows: 4)\n",
            "💾 Saved interaction to chat_interactions.xlsx (Total rows: 5)\n",
            "💾 Saved interaction to chat_interactions.xlsx (Total rows: 6)\n"
          ]
        }
      ],
      "source": [
        "def test_llm():\n",
        "    \"\"\"Test function to verify LLM is working\"\"\"\n",
        "    print(\"Testing LLM connection...\")\n",
        "    response = get_llm_response(\"Hello! Please respond with a brief greeting.\")\n",
        "    print(f\"LLM Response: {response}\")\n",
        "    return response\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test the connection first\n",
        "    print(\"🔧 Testing LLM connection...\")\n",
        "    test_result = test_llm()\n",
        "\n",
        "    if \"Error:\" not in test_result:\n",
        "        print(\"✅ LLM connection successful!\")\n",
        "        print(\"📊 Initializing Excel database...\")\n",
        "        initialize_excel_database()\n",
        "        print(\"🚀 Starting Gradio interface...\")\n",
        "\n",
        "        # Create and launch the interface\n",
        "        demo = create_basic_interface()\n",
        "        demo.launch(\n",
        "            share=True)\n",
        "    else:\n",
        "        print(\"❌ LLM connection failed!\")\n",
        "        print(f\"Error: {test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81323221-eb7f-4c87-ab4b-d03b875becb0",
      "metadata": {
        "id": "81323221-eb7f-4c87-ab4b-d03b875becb0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}